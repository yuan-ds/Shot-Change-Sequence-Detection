{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Baseline_Approach_Resnet34_12channels_direct.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7badc3cb"
      },
      "source": [
        "## 1. Libraries and Setup"
      ],
      "id": "7badc3cb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuO32Xm2fb1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0db7df3-c913-4ecc-beac-0c5ab83d7aaa"
      },
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "AuO32Xm2fb1z",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIlv-QiNgNt7"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/converted_224x224.tar.gz /content\n",
        "%cd /content\n",
        "!tar -xvzf converted_224x224.tar.gz"
      ],
      "id": "jIlv-QiNgNt7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2AK4w8Nh-4Q"
      },
      "source": [
        "!ls converted_224x224/"
      ],
      "id": "a2AK4w8Nh-4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "812ec14e"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pdb\n",
        "import gc\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "id": "812ec14e",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5972057",
        "outputId": "49400d8f-6267-4cde-e1d5-1fb82ea92641"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "num_workers = 8 if cuda else 0\n",
        "\n",
        "print(\"Cuda = \", str(cuda), \" with num_workers = \", str(num_workers),  \" system version = \", sys.version)"
      ],
      "id": "c5972057",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda =  True  with num_workers =  8  system version =  3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e71e53e8"
      },
      "source": [
        "## 2. Data Loading"
      ],
      "id": "e71e53e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bdee1e8"
      },
      "source": [
        "### 2.1 Load Data"
      ],
      "id": "3bdee1e8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e874ee1"
      },
      "source": [
        "np.random.seed(0)\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/dataset/3+1.csv\")\n",
        "df = df.iloc[:, 1:]\n",
        "\n",
        "train_end = int(len(df)*0.7)\n",
        "val_end = int(len(df)*0.85)\n",
        "train_data = df[:train_end]\n",
        "val_data = df[train_end:val_end]\n",
        "test_data = df[val_end:]"
      ],
      "id": "6e874ee1",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e669450b"
      },
      "source": [
        "train_data = train_data.reset_index().drop('Unnamed: 0.1',1).drop('index',1)\n",
        "val_data = val_data.reset_index().drop('Unnamed: 0.1',1).drop('index',1)\n",
        "test_data = test_data.reset_index().drop('Unnamed: 0.1',1).drop('index',1)"
      ],
      "id": "e669450b",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "1gs_EeHEuiP7",
        "outputId": "9a0724ef-d0eb-44a3-e789-9e5ec929509b"
      },
      "source": [
        "test_data"
      ],
      "id": "1gs_EeHEuiP7",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frames</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>('frame_149932.jpg', 'frame_149907.jpg', 'fram...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>('frame_149933.jpg', 'frame_152295.jpg', 'fram...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>('frame_149903.jpg', 'frame_152323.jpg', 'fram...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>('frame_152463.jpg', 'frame_149941.jpg', 'fram...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>('frame_149930.jpg', 'frame_152761.jpg', 'fram...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18049</th>\n",
              "      <td>('frame_174654.jpg', 'frame_180809.jpg', 'fram...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18050</th>\n",
              "      <td>('frame_174580.jpg', 'frame_174619.jpg', 'fram...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18051</th>\n",
              "      <td>('frame_180890.jpg', 'frame_174567.jpg', 'fram...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18052</th>\n",
              "      <td>('frame_174586.jpg', 'frame_174612.jpg', 'fram...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18053</th>\n",
              "      <td>('frame_181333.jpg', 'frame_174654.jpg', 'fram...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18054 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  frames  label\n",
              "0      ('frame_149932.jpg', 'frame_149907.jpg', 'fram...      7\n",
              "1      ('frame_149933.jpg', 'frame_152295.jpg', 'fram...     10\n",
              "2      ('frame_149903.jpg', 'frame_152323.jpg', 'fram...      4\n",
              "3      ('frame_152463.jpg', 'frame_149941.jpg', 'fram...     22\n",
              "4      ('frame_149930.jpg', 'frame_152761.jpg', 'fram...     11\n",
              "...                                                  ...    ...\n",
              "18049  ('frame_174654.jpg', 'frame_180809.jpg', 'fram...     17\n",
              "18050  ('frame_174580.jpg', 'frame_174619.jpg', 'fram...      3\n",
              "18051  ('frame_180890.jpg', 'frame_174567.jpg', 'fram...     19\n",
              "18052  ('frame_174586.jpg', 'frame_174612.jpg', 'fram...      1\n",
              "18053  ('frame_181333.jpg', 'frame_174654.jpg', 'fram...     23\n",
              "\n",
              "[18054 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15cbf79"
      },
      "source": [
        "### 2.2 Custom Dataset Class"
      ],
      "id": "f15cbf79"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK6gHTVopf7M"
      },
      "source": [
        "# cur_dir = \"data/qscale31_unique/\"\n",
        "cur_dir = \"converted_224x224/\""
      ],
      "id": "RK6gHTVopf7M",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21554c7"
      },
      "source": [
        "# Define dataset class\n",
        "class MyDataSet(Dataset):\n",
        "\n",
        "    # load the dataset\n",
        "    def __init__(self, data, **kwargs):\n",
        "        self.X = data[\"frames\"]\n",
        "        self.Y = data[\"label\"]\n",
        "\n",
        "    # get number of items/rows in dataset\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.X[index], self.Y[index]\n",
        "        for c in [\"(\",\")\",\",\",\"'\"]:\n",
        "            x = x.replace(c, \"\")\n",
        "        x = x.split(\" \")\n",
        "        images = []\n",
        "        for img_file in x:\n",
        "            img = Image.open(cur_dir + img_file)\n",
        "            img = torchvision.transforms.ToTensor()(img)\n",
        "            images.extend(img)\n",
        "        x = torch.stack(images)\n",
        "        return x, y\n",
        "    "
      ],
      "id": "c21554c7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tpf6FW9nr7J",
        "outputId": "4bbbe564-9cba-4b3e-e680-c8ca449a8132"
      },
      "source": [
        "train_set = MyDataSet(train_data)\n",
        "train_set[0][0].shape"
      ],
      "id": "3Tpf6FW9nr7J",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d6b5efe"
      },
      "source": [
        "### 2.3 Dataloader"
      ],
      "id": "6d6b5efe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fb2a207"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# training data\n",
        "train_set = MyDataSet(train_data)\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=8)\n",
        "\n",
        "# validation data\n",
        "val_set = MyDataSet(val_data)\n",
        "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size, num_workers=8)\n",
        "\n",
        "# test data\n",
        "test_set = MyDataSet(test_data)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size, num_workers=8)"
      ],
      "id": "4fb2a207",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a589effb"
      },
      "source": [
        "## 3. Model"
      ],
      "id": "a589effb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c94574d"
      },
      "source": [
        "# This is the simplest possible residual block, with only one CNN layer.\n",
        "# Looking at the paper, you can extend this block to have more layers, bottleneck, grouped convs (from shufflenet), etc.\n",
        "# Or even look at more recent papers like resnext, regnet, resnest, senet, etc.\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel,stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False, dilation = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu1 = nn.ReLU(inplace = True)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding= 1, bias=False, dilation = 1)\n",
        "        self.bn2 =  nn.BatchNorm2d(out_channel)\n",
        "        if stride == 1:\n",
        "            self.shortcut = nn.Identity()\n",
        "        else:\n",
        "            self.shortcut = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride)\n",
        "        self.relu2 = nn.ReLU(inplace = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        shortcut = self.shortcut(x) \n",
        "        out = self.relu2(out + shortcut)\n",
        "        \n",
        "        return out"
      ],
      "id": "7c94574d",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8386991f"
      },
      "source": [
        "# This has hard-coded hidden feature sizes.\n",
        "# You can extend this to take in a list of hidden sizes as argument if you want.\n",
        "class ClassificationNetwork(nn.Module):\n",
        "    def __init__(self, in_features, num_classes,feat_dim = 512):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_features, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,128,stride = 2),\n",
        "            ResidualBlock(128,128),\n",
        "            ResidualBlock(128,128),\n",
        "            ResidualBlock(128,128),\n",
        "            ResidualBlock(128,256,stride = 2),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,512,stride = 2),\n",
        "            ResidualBlock(512,512),\n",
        "            ResidualBlock(512,512),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), # For each channel, collapses (averages) the entire feature map (height & width) to 1x1\n",
        "            nn.Flatten(1), # the above ends up with batch_size x 512 x 1 x 1, flatten to batch_size x 512\n",
        "        )\n",
        "        self.linear_emb = nn.Linear(512, feat_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.linear_output_1 = nn.Linear(512,512)\n",
        "        self.relu_output = nn.ReLU(inplace=True)\n",
        "        self.dropout_output = nn.Dropout(p=0.4)\n",
        "        self.linear_output_2 = nn.Linear(512,num_classes)\n",
        "        # self.fc = nn.Linear(512,num_classes)\n",
        "        \n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          elif isinstance(m, (nn.BatchNorm2d)):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0) \n",
        "\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, ResidualBlock):\n",
        "            nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]  \n",
        "\n",
        "    def forward(self, x, return_embedding=False):\n",
        "        embedding = self.layers(x)\n",
        "        embedding_out = self.linear_emb(embedding)\n",
        "        embedding_out = self.relu(embedding_out)\n",
        "\n",
        "        output = self.linear_output_1(embedding)\n",
        "        output = self.relu_output(output)\n",
        "        output = self.dropout_output(output)\n",
        "        output = self.linear_output_2(output)\n",
        "        # output = self.fc(embedding)\n",
        "\n",
        "        if return_embedding:\n",
        "            return embedding_out,output\n",
        "        else:\n",
        "            return output "
      ],
      "id": "8386991f",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9kNdjdnvVgk"
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, in_channels, embedding, num_images, num_classes):\n",
        "        super().__init__()\n",
        "        self.cnn = ClassificationNetwork(in_channels, embedding)\n",
        "        self.mlp = nn.Sequential(nn.Linear(embedding*num_images, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = x[:, 0:3, :, :]\n",
        "      x2 = x[:, 3:6, :, :]\n",
        "      x3 = x[:, 6:9, :, :]\n",
        "      x4 = x[:, 9:12, :, :]\n",
        "\n",
        "      out1 = self.cnn(x1)\n",
        "      out2 = self.cnn(x2)\n",
        "      out3 = self.cnn(x3)\n",
        "      out4 = self.cnn(x4)\n",
        "\n",
        "      out = torch.cat([out1, out2, out3, out4], axis=1)\n",
        "      logits = self.mlp(out)\n",
        "      return logits"
      ],
      "id": "y9kNdjdnvVgk",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "964a4c9e"
      },
      "source": [
        "numEpochs = 500\n",
        "in_features = 3 # TODO: change RGB channels according to num of frames\n",
        "embedding = 128\n",
        "\n",
        "learningRate = 0.1\n",
        "weightDecay = 1e-4\n",
        "\n",
        "num_images = 4\n",
        "num_classes = 24\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "network = Network(in_features, embedding, num_images, num_classes)\n",
        "#network.load_state_dict(torch.load(\"model_checkpoints/resnet34/lr_0.1-2/model_2.pt\"))\n",
        "network = network.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.7, verbose=True)"
      ],
      "id": "964a4c9e",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7b85b7de",
        "outputId": "26e9f122-3e6b-4348-928d-52fefd153da7"
      },
      "source": [
        "# Train!\n",
        "max_val_acc = 0\n",
        "for epoch in range(numEpochs):\n",
        "    # Train\n",
        "    network.train()\n",
        "    avg_loss = 0.0\n",
        "    avg_train_acc = 0.0\n",
        "    for batch_num, (x, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = network(x)\n",
        "        num_train_correct = (torch.argmax(outputs, axis=1) == y).sum().item()\n",
        "        num_labels = len(y)\n",
        "        avg_train_acc += (num_train_correct/num_labels)\n",
        "\n",
        "        loss = criterion(outputs, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "        if batch_num % 50 == 49:\n",
        "            print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}\\tTraining Accuracy : {:.4f}'.format(epoch, batch_num+1, avg_loss/50, avg_train_acc/50))\n",
        "            avg_loss = 0.0\n",
        "            avg_train_acc = 0.0\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        del x\n",
        "        del y\n",
        "        del loss\n",
        "    \n",
        "    # Validate\n",
        "    with torch.no_grad():\n",
        "        network.eval()\n",
        "        avg_val_loss = 0.0\n",
        "        num_correct = 0\n",
        "        for batch_num, (x, y) in enumerate(val_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = network(x)\n",
        "            num_correct += (torch.argmax(outputs, axis=1) == y).sum().item()\n",
        "            loss = criterion(outputs, y.long())\n",
        "            avg_val_loss += loss.item()\n",
        "            torch.cuda.empty_cache()\n",
        "            del x\n",
        "            del y\n",
        "\n",
        "        avg_val_loss = avg_val_loss / len(val_loader)\n",
        "        val_acc = num_correct / len(val_set)\n",
        "        checkpoint_name = \"/content/gdrive/MyDrive/baseline_12channels/model_\" + str(epoch) + \".pt\"\n",
        "        torch.save(network.state_dict(), checkpoint_name)\n",
        "        if val_acc > max_val_acc:\n",
        "            max_val_acc = val_acc\n",
        "            torch.save(network.state_dict(), \"/content/gdrive/MyDrive/baseline_12channels/best_model.pt\")\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "    print('Epoch: {}, Validation Loss: {:.3f}, Validation Accuracy: {:.3f}'.format(epoch, avg_val_loss, val_acc))"
      ],
      "id": "7b85b7de",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\tBatch: 50\tAvg-Loss: 3.1829\tTraining Accuracy : 0.0347\n",
            "Epoch: 0\tBatch: 100\tAvg-Loss: 3.1820\tTraining Accuracy : 0.0384\n",
            "Epoch: 0\tBatch: 150\tAvg-Loss: 3.1835\tTraining Accuracy : 0.0416\n",
            "Epoch: 0\tBatch: 200\tAvg-Loss: 3.1823\tTraining Accuracy : 0.0391\n",
            "Epoch: 0\tBatch: 250\tAvg-Loss: 3.1834\tTraining Accuracy : 0.0444\n",
            "Epoch: 0\tBatch: 300\tAvg-Loss: 3.1862\tTraining Accuracy : 0.0350\n",
            "Epoch: 0\tBatch: 350\tAvg-Loss: 3.1804\tTraining Accuracy : 0.0384\n",
            "Epoch: 0\tBatch: 400\tAvg-Loss: 3.1814\tTraining Accuracy : 0.0400\n",
            "Epoch: 0\tBatch: 450\tAvg-Loss: 3.1841\tTraining Accuracy : 0.0406\n",
            "Epoch: 0\tBatch: 500\tAvg-Loss: 3.1802\tTraining Accuracy : 0.0391\n",
            "Epoch: 0\tBatch: 550\tAvg-Loss: 3.1801\tTraining Accuracy : 0.0503\n",
            "Epoch: 0\tBatch: 600\tAvg-Loss: 3.1823\tTraining Accuracy : 0.0431\n",
            "Epoch: 0\tBatch: 650\tAvg-Loss: 3.1824\tTraining Accuracy : 0.0394\n",
            "Epoch: 0\tBatch: 700\tAvg-Loss: 3.1821\tTraining Accuracy : 0.0516\n",
            "Epoch: 0\tBatch: 750\tAvg-Loss: 3.1807\tTraining Accuracy : 0.0447\n",
            "Epoch: 0\tBatch: 800\tAvg-Loss: 3.1807\tTraining Accuracy : 0.0525\n",
            "Epoch: 0\tBatch: 850\tAvg-Loss: 3.1758\tTraining Accuracy : 0.0488\n",
            "Epoch: 0\tBatch: 900\tAvg-Loss: 3.1829\tTraining Accuracy : 0.0434\n",
            "Epoch: 0\tBatch: 950\tAvg-Loss: 3.1782\tTraining Accuracy : 0.0575\n",
            "Epoch: 0\tBatch: 1000\tAvg-Loss: 3.1794\tTraining Accuracy : 0.0531\n",
            "Epoch: 0\tBatch: 1050\tAvg-Loss: 3.1740\tTraining Accuracy : 0.0600\n",
            "Epoch: 0\tBatch: 1100\tAvg-Loss: 3.1728\tTraining Accuracy : 0.0566\n",
            "Epoch: 0\tBatch: 1150\tAvg-Loss: 3.1726\tTraining Accuracy : 0.0553\n",
            "Epoch: 0\tBatch: 1200\tAvg-Loss: 3.1777\tTraining Accuracy : 0.0609\n",
            "Epoch: 0\tBatch: 1250\tAvg-Loss: 3.1580\tTraining Accuracy : 0.0581\n",
            "Epoch: 0\tBatch: 1300\tAvg-Loss: 3.1355\tTraining Accuracy : 0.0797\n",
            "Epoch: 0, Validation Loss: 3.202, Validation Accuracy: 0.045\n",
            "Epoch: 1\tBatch: 50\tAvg-Loss: 3.1250\tTraining Accuracy : 0.0816\n",
            "Epoch: 1\tBatch: 100\tAvg-Loss: 3.1135\tTraining Accuracy : 0.0741\n",
            "Epoch: 1\tBatch: 150\tAvg-Loss: 3.0707\tTraining Accuracy : 0.0887\n",
            "Epoch: 1\tBatch: 200\tAvg-Loss: 3.0499\tTraining Accuracy : 0.0959\n",
            "Epoch: 1\tBatch: 250\tAvg-Loss: 3.0231\tTraining Accuracy : 0.1147\n",
            "Epoch: 1\tBatch: 300\tAvg-Loss: 3.0144\tTraining Accuracy : 0.1091\n",
            "Epoch: 1\tBatch: 350\tAvg-Loss: 2.9644\tTraining Accuracy : 0.1203\n",
            "Epoch: 1\tBatch: 400\tAvg-Loss: 2.9490\tTraining Accuracy : 0.1147\n",
            "Epoch: 1\tBatch: 450\tAvg-Loss: 2.9234\tTraining Accuracy : 0.1219\n",
            "Epoch: 1\tBatch: 500\tAvg-Loss: 2.8624\tTraining Accuracy : 0.1447\n",
            "Epoch: 1\tBatch: 550\tAvg-Loss: 2.8322\tTraining Accuracy : 0.1462\n",
            "Epoch: 1\tBatch: 600\tAvg-Loss: 2.7927\tTraining Accuracy : 0.1494\n",
            "Epoch: 1\tBatch: 650\tAvg-Loss: 2.7081\tTraining Accuracy : 0.1509\n",
            "Epoch: 1\tBatch: 700\tAvg-Loss: 2.6766\tTraining Accuracy : 0.1688\n",
            "Epoch: 1\tBatch: 750\tAvg-Loss: 2.6353\tTraining Accuracy : 0.1731\n",
            "Epoch: 1\tBatch: 800\tAvg-Loss: 2.5887\tTraining Accuracy : 0.1797\n",
            "Epoch: 1\tBatch: 850\tAvg-Loss: 2.4969\tTraining Accuracy : 0.1934\n",
            "Epoch: 1\tBatch: 900\tAvg-Loss: 2.5189\tTraining Accuracy : 0.1963\n",
            "Epoch: 1\tBatch: 950\tAvg-Loss: 2.4602\tTraining Accuracy : 0.2019\n",
            "Epoch: 1\tBatch: 1000\tAvg-Loss: 2.3753\tTraining Accuracy : 0.2303\n",
            "Epoch: 1\tBatch: 1050\tAvg-Loss: 2.3492\tTraining Accuracy : 0.2391\n",
            "Epoch: 1\tBatch: 1100\tAvg-Loss: 2.3008\tTraining Accuracy : 0.2422\n",
            "Epoch: 1\tBatch: 1150\tAvg-Loss: 2.2433\tTraining Accuracy : 0.2591\n",
            "Epoch: 1\tBatch: 1200\tAvg-Loss: 2.2186\tTraining Accuracy : 0.2634\n",
            "Epoch: 1\tBatch: 1250\tAvg-Loss: 2.1710\tTraining Accuracy : 0.2772\n",
            "Epoch: 1\tBatch: 1300\tAvg-Loss: 2.2248\tTraining Accuracy : 0.2687\n",
            "Epoch: 1, Validation Loss: 4.296, Validation Accuracy: 0.063\n",
            "Epoch: 2\tBatch: 50\tAvg-Loss: 2.0980\tTraining Accuracy : 0.2991\n",
            "Epoch: 2\tBatch: 100\tAvg-Loss: 2.0667\tTraining Accuracy : 0.2900\n",
            "Epoch: 2\tBatch: 150\tAvg-Loss: 2.0680\tTraining Accuracy : 0.2941\n",
            "Epoch: 2\tBatch: 200\tAvg-Loss: 2.0091\tTraining Accuracy : 0.3100\n",
            "Epoch: 2\tBatch: 250\tAvg-Loss: 2.0099\tTraining Accuracy : 0.3259\n",
            "Epoch: 2\tBatch: 300\tAvg-Loss: 1.9678\tTraining Accuracy : 0.3278\n",
            "Epoch: 2\tBatch: 350\tAvg-Loss: 1.9623\tTraining Accuracy : 0.3287\n",
            "Epoch: 2\tBatch: 400\tAvg-Loss: 1.8994\tTraining Accuracy : 0.3525\n",
            "Epoch: 2\tBatch: 450\tAvg-Loss: 1.8239\tTraining Accuracy : 0.3672\n",
            "Epoch: 2\tBatch: 500\tAvg-Loss: 1.8194\tTraining Accuracy : 0.3681\n",
            "Epoch: 2\tBatch: 550\tAvg-Loss: 1.8050\tTraining Accuracy : 0.3663\n",
            "Epoch: 2\tBatch: 600\tAvg-Loss: 1.8138\tTraining Accuracy : 0.3809\n",
            "Epoch: 2\tBatch: 650\tAvg-Loss: 1.7883\tTraining Accuracy : 0.3806\n",
            "Epoch: 2\tBatch: 700\tAvg-Loss: 1.7139\tTraining Accuracy : 0.4097\n",
            "Epoch: 2\tBatch: 750\tAvg-Loss: 1.7266\tTraining Accuracy : 0.3972\n",
            "Epoch: 2\tBatch: 800\tAvg-Loss: 1.6516\tTraining Accuracy : 0.4200\n",
            "Epoch: 2\tBatch: 850\tAvg-Loss: 1.7900\tTraining Accuracy : 0.3947\n",
            "Epoch: 2\tBatch: 900\tAvg-Loss: 1.6418\tTraining Accuracy : 0.4356\n",
            "Epoch: 2\tBatch: 950\tAvg-Loss: 1.6581\tTraining Accuracy : 0.4203\n",
            "Epoch: 2\tBatch: 1000\tAvg-Loss: 1.6366\tTraining Accuracy : 0.4284\n",
            "Epoch: 2\tBatch: 1050\tAvg-Loss: 1.5650\tTraining Accuracy : 0.4447\n",
            "Epoch: 2\tBatch: 1100\tAvg-Loss: 1.6002\tTraining Accuracy : 0.4375\n",
            "Epoch: 2\tBatch: 1150\tAvg-Loss: 1.5483\tTraining Accuracy : 0.4478\n",
            "Epoch: 2\tBatch: 1200\tAvg-Loss: 1.5674\tTraining Accuracy : 0.4472\n",
            "Epoch: 2\tBatch: 1250\tAvg-Loss: 1.5452\tTraining Accuracy : 0.4522\n",
            "Epoch: 2\tBatch: 1300\tAvg-Loss: 1.4850\tTraining Accuracy : 0.4741\n",
            "Epoch: 2, Validation Loss: 6.109, Validation Accuracy: 0.066\n",
            "Epoch: 3\tBatch: 50\tAvg-Loss: 1.4821\tTraining Accuracy : 0.4756\n",
            "Epoch: 3\tBatch: 100\tAvg-Loss: 1.4509\tTraining Accuracy : 0.4981\n",
            "Epoch: 3\tBatch: 150\tAvg-Loss: 1.3934\tTraining Accuracy : 0.5194\n",
            "Epoch: 3\tBatch: 200\tAvg-Loss: 1.3630\tTraining Accuracy : 0.5150\n",
            "Epoch: 3\tBatch: 250\tAvg-Loss: 1.4275\tTraining Accuracy : 0.5019\n",
            "Epoch: 3\tBatch: 300\tAvg-Loss: 1.3974\tTraining Accuracy : 0.5022\n",
            "Epoch: 3\tBatch: 350\tAvg-Loss: 1.3980\tTraining Accuracy : 0.5138\n",
            "Epoch: 3\tBatch: 400\tAvg-Loss: 1.3652\tTraining Accuracy : 0.5181\n",
            "Epoch: 3\tBatch: 450\tAvg-Loss: 1.3214\tTraining Accuracy : 0.5328\n",
            "Epoch: 3\tBatch: 500\tAvg-Loss: 1.3687\tTraining Accuracy : 0.5038\n",
            "Epoch: 3\tBatch: 550\tAvg-Loss: 1.3108\tTraining Accuracy : 0.5219\n",
            "Epoch: 3\tBatch: 600\tAvg-Loss: 1.2961\tTraining Accuracy : 0.5413\n",
            "Epoch: 3\tBatch: 650\tAvg-Loss: 1.2655\tTraining Accuracy : 0.5491\n",
            "Epoch: 3\tBatch: 700\tAvg-Loss: 1.2578\tTraining Accuracy : 0.5563\n",
            "Epoch: 3\tBatch: 750\tAvg-Loss: 1.2415\tTraining Accuracy : 0.5503\n",
            "Epoch: 3\tBatch: 800\tAvg-Loss: 1.2849\tTraining Accuracy : 0.5428\n",
            "Epoch: 3\tBatch: 850\tAvg-Loss: 1.2346\tTraining Accuracy : 0.5644\n",
            "Epoch: 3\tBatch: 900\tAvg-Loss: 1.2579\tTraining Accuracy : 0.5509\n",
            "Epoch: 3\tBatch: 950\tAvg-Loss: 1.1704\tTraining Accuracy : 0.5706\n",
            "Epoch: 3\tBatch: 1000\tAvg-Loss: 1.1954\tTraining Accuracy : 0.5700\n",
            "Epoch: 3\tBatch: 1050\tAvg-Loss: 1.1482\tTraining Accuracy : 0.5819\n",
            "Epoch: 3\tBatch: 1100\tAvg-Loss: 1.2058\tTraining Accuracy : 0.5647\n",
            "Epoch: 3\tBatch: 1150\tAvg-Loss: 1.2266\tTraining Accuracy : 0.5641\n",
            "Epoch: 3\tBatch: 1200\tAvg-Loss: 1.1871\tTraining Accuracy : 0.5822\n",
            "Epoch: 3\tBatch: 1250\tAvg-Loss: 1.1814\tTraining Accuracy : 0.5825\n",
            "Epoch: 3\tBatch: 1300\tAvg-Loss: 1.1461\tTraining Accuracy : 0.5837\n",
            "Epoch: 3, Validation Loss: 8.708, Validation Accuracy: 0.069\n",
            "Epoch: 4\tBatch: 50\tAvg-Loss: 1.1339\tTraining Accuracy : 0.5953\n",
            "Epoch: 4\tBatch: 100\tAvg-Loss: 1.1080\tTraining Accuracy : 0.5928\n",
            "Epoch: 4\tBatch: 150\tAvg-Loss: 1.1210\tTraining Accuracy : 0.6059\n",
            "Epoch: 4\tBatch: 200\tAvg-Loss: 1.0932\tTraining Accuracy : 0.6009\n",
            "Epoch: 4\tBatch: 250\tAvg-Loss: 1.1247\tTraining Accuracy : 0.6016\n",
            "Epoch: 4\tBatch: 300\tAvg-Loss: 1.0511\tTraining Accuracy : 0.6244\n",
            "Epoch: 4\tBatch: 350\tAvg-Loss: 1.0634\tTraining Accuracy : 0.6212\n",
            "Epoch: 4\tBatch: 400\tAvg-Loss: 1.0652\tTraining Accuracy : 0.6094\n",
            "Epoch: 4\tBatch: 450\tAvg-Loss: 1.1002\tTraining Accuracy : 0.6100\n",
            "Epoch: 4\tBatch: 500\tAvg-Loss: 1.0519\tTraining Accuracy : 0.6122\n",
            "Epoch: 4\tBatch: 550\tAvg-Loss: 1.0107\tTraining Accuracy : 0.6306\n",
            "Epoch: 4\tBatch: 600\tAvg-Loss: 1.0313\tTraining Accuracy : 0.6159\n",
            "Epoch: 4\tBatch: 650\tAvg-Loss: 1.0115\tTraining Accuracy : 0.6353\n",
            "Epoch: 4\tBatch: 700\tAvg-Loss: 1.0160\tTraining Accuracy : 0.6303\n",
            "Epoch: 4\tBatch: 750\tAvg-Loss: 1.0309\tTraining Accuracy : 0.6372\n",
            "Epoch: 4\tBatch: 800\tAvg-Loss: 0.9455\tTraining Accuracy : 0.6550\n",
            "Epoch: 4\tBatch: 850\tAvg-Loss: 0.9947\tTraining Accuracy : 0.6378\n",
            "Epoch: 4\tBatch: 900\tAvg-Loss: 0.9788\tTraining Accuracy : 0.6587\n",
            "Epoch: 4\tBatch: 950\tAvg-Loss: 1.0255\tTraining Accuracy : 0.6206\n",
            "Epoch: 4\tBatch: 1000\tAvg-Loss: 0.9472\tTraining Accuracy : 0.6550\n",
            "Epoch: 4\tBatch: 1050\tAvg-Loss: 0.9641\tTraining Accuracy : 0.6528\n",
            "Epoch: 4\tBatch: 1100\tAvg-Loss: 0.9559\tTraining Accuracy : 0.6497\n",
            "Epoch: 4\tBatch: 1150\tAvg-Loss: 0.9480\tTraining Accuracy : 0.6525\n",
            "Epoch: 4\tBatch: 1200\tAvg-Loss: 0.9307\tTraining Accuracy : 0.6609\n",
            "Epoch: 4\tBatch: 1250\tAvg-Loss: 0.9671\tTraining Accuracy : 0.6462\n",
            "Epoch: 4\tBatch: 1300\tAvg-Loss: 0.9406\tTraining Accuracy : 0.6516\n",
            "Epoch     5: reducing learning rate of group 0 to 7.0000e-02.\n",
            "Epoch: 4, Validation Loss: 5.896, Validation Accuracy: 0.073\n",
            "Epoch: 5\tBatch: 50\tAvg-Loss: 0.8431\tTraining Accuracy : 0.6909\n",
            "Epoch: 5\tBatch: 100\tAvg-Loss: 0.7493\tTraining Accuracy : 0.7172\n",
            "Epoch: 5\tBatch: 150\tAvg-Loss: 0.7471\tTraining Accuracy : 0.7269\n",
            "Epoch: 5\tBatch: 200\tAvg-Loss: 0.7286\tTraining Accuracy : 0.7316\n",
            "Epoch: 5\tBatch: 250\tAvg-Loss: 0.7053\tTraining Accuracy : 0.7331\n",
            "Epoch: 5\tBatch: 300\tAvg-Loss: 0.7095\tTraining Accuracy : 0.7241\n",
            "Epoch: 5\tBatch: 350\tAvg-Loss: 0.7013\tTraining Accuracy : 0.7462\n",
            "Epoch: 5\tBatch: 400\tAvg-Loss: 0.7141\tTraining Accuracy : 0.7412\n",
            "Epoch: 5\tBatch: 450\tAvg-Loss: 0.7069\tTraining Accuracy : 0.7378\n",
            "Epoch: 5\tBatch: 500\tAvg-Loss: 0.7579\tTraining Accuracy : 0.7284\n",
            "Epoch: 5\tBatch: 550\tAvg-Loss: 0.6855\tTraining Accuracy : 0.7541\n",
            "Epoch: 5\tBatch: 600\tAvg-Loss: 0.6599\tTraining Accuracy : 0.7556\n",
            "Epoch: 5\tBatch: 650\tAvg-Loss: 0.6536\tTraining Accuracy : 0.7612\n",
            "Epoch: 5\tBatch: 700\tAvg-Loss: 0.6642\tTraining Accuracy : 0.7612\n",
            "Epoch: 5\tBatch: 750\tAvg-Loss: 0.6460\tTraining Accuracy : 0.7647\n",
            "Epoch: 5\tBatch: 800\tAvg-Loss: 0.6620\tTraining Accuracy : 0.7572\n",
            "Epoch: 5\tBatch: 850\tAvg-Loss: 0.6367\tTraining Accuracy : 0.7697\n",
            "Epoch: 5\tBatch: 900\tAvg-Loss: 0.6490\tTraining Accuracy : 0.7575\n",
            "Epoch: 5\tBatch: 950\tAvg-Loss: 0.6349\tTraining Accuracy : 0.7631\n",
            "Epoch: 5\tBatch: 1000\tAvg-Loss: 0.6606\tTraining Accuracy : 0.7631\n",
            "Epoch: 5\tBatch: 1050\tAvg-Loss: 0.7010\tTraining Accuracy : 0.7462\n",
            "Epoch: 5\tBatch: 1100\tAvg-Loss: 0.6674\tTraining Accuracy : 0.7628\n",
            "Epoch: 5\tBatch: 1150\tAvg-Loss: 0.6223\tTraining Accuracy : 0.7772\n",
            "Epoch: 5\tBatch: 1200\tAvg-Loss: 0.5992\tTraining Accuracy : 0.7709\n",
            "Epoch: 5\tBatch: 1250\tAvg-Loss: 0.6123\tTraining Accuracy : 0.7744\n",
            "Epoch: 5\tBatch: 1300\tAvg-Loss: 0.6371\tTraining Accuracy : 0.7688\n",
            "Epoch: 5, Validation Loss: 8.328, Validation Accuracy: 0.079\n",
            "Epoch: 6\tBatch: 50\tAvg-Loss: 0.5805\tTraining Accuracy : 0.7856\n",
            "Epoch: 6\tBatch: 100\tAvg-Loss: 0.6057\tTraining Accuracy : 0.7847\n",
            "Epoch: 6\tBatch: 150\tAvg-Loss: 0.5461\tTraining Accuracy : 0.7963\n",
            "Epoch: 6\tBatch: 200\tAvg-Loss: 0.5881\tTraining Accuracy : 0.7794\n",
            "Epoch: 6\tBatch: 250\tAvg-Loss: 0.5833\tTraining Accuracy : 0.7878\n",
            "Epoch: 6\tBatch: 300\tAvg-Loss: 0.5686\tTraining Accuracy : 0.7837\n",
            "Epoch: 6\tBatch: 350\tAvg-Loss: 0.5332\tTraining Accuracy : 0.8041\n",
            "Epoch: 6\tBatch: 400\tAvg-Loss: 0.5325\tTraining Accuracy : 0.8081\n",
            "Epoch: 6\tBatch: 450\tAvg-Loss: 0.5886\tTraining Accuracy : 0.7806\n",
            "Epoch: 6\tBatch: 500\tAvg-Loss: 0.6014\tTraining Accuracy : 0.7759\n",
            "Epoch: 6\tBatch: 550\tAvg-Loss: 0.5570\tTraining Accuracy : 0.7909\n",
            "Epoch: 6\tBatch: 600\tAvg-Loss: 0.5925\tTraining Accuracy : 0.7869\n",
            "Epoch: 6\tBatch: 650\tAvg-Loss: 0.5764\tTraining Accuracy : 0.7947\n",
            "Epoch: 6\tBatch: 700\tAvg-Loss: 0.5303\tTraining Accuracy : 0.8031\n",
            "Epoch: 6\tBatch: 750\tAvg-Loss: 0.5478\tTraining Accuracy : 0.7987\n",
            "Epoch: 6\tBatch: 800\tAvg-Loss: 0.5562\tTraining Accuracy : 0.7931\n",
            "Epoch: 6\tBatch: 850\tAvg-Loss: 0.5783\tTraining Accuracy : 0.7900\n",
            "Epoch: 6\tBatch: 900\tAvg-Loss: 0.5571\tTraining Accuracy : 0.8022\n",
            "Epoch: 6\tBatch: 950\tAvg-Loss: 0.5419\tTraining Accuracy : 0.8084\n",
            "Epoch: 6\tBatch: 1000\tAvg-Loss: 0.5458\tTraining Accuracy : 0.7922\n",
            "Epoch: 6\tBatch: 1050\tAvg-Loss: 0.5601\tTraining Accuracy : 0.7881\n",
            "Epoch: 6\tBatch: 1100\tAvg-Loss: 0.5217\tTraining Accuracy : 0.7941\n",
            "Epoch: 6\tBatch: 1150\tAvg-Loss: 0.5159\tTraining Accuracy : 0.8087\n",
            "Epoch: 6\tBatch: 1200\tAvg-Loss: 0.5487\tTraining Accuracy : 0.8019\n",
            "Epoch: 6\tBatch: 1250\tAvg-Loss: 0.5104\tTraining Accuracy : 0.8053\n",
            "Epoch: 6\tBatch: 1300\tAvg-Loss: 0.5678\tTraining Accuracy : 0.7991\n",
            "Epoch: 6, Validation Loss: 8.298, Validation Accuracy: 0.076\n",
            "Epoch: 7\tBatch: 50\tAvg-Loss: 0.4971\tTraining Accuracy : 0.8134\n",
            "Epoch: 7\tBatch: 100\tAvg-Loss: 0.5059\tTraining Accuracy : 0.8137\n",
            "Epoch: 7\tBatch: 150\tAvg-Loss: 0.5376\tTraining Accuracy : 0.8097\n",
            "Epoch: 7\tBatch: 200\tAvg-Loss: 0.5160\tTraining Accuracy : 0.8163\n",
            "Epoch: 7\tBatch: 250\tAvg-Loss: 0.4984\tTraining Accuracy : 0.8253\n",
            "Epoch: 7\tBatch: 300\tAvg-Loss: 0.4931\tTraining Accuracy : 0.8241\n",
            "Epoch: 7\tBatch: 350\tAvg-Loss: 0.5080\tTraining Accuracy : 0.8134\n",
            "Epoch: 7\tBatch: 400\tAvg-Loss: 0.5239\tTraining Accuracy : 0.8119\n",
            "Epoch: 7\tBatch: 450\tAvg-Loss: 0.5333\tTraining Accuracy : 0.8122\n",
            "Epoch: 7\tBatch: 500\tAvg-Loss: 0.4759\tTraining Accuracy : 0.8181\n",
            "Epoch: 7\tBatch: 550\tAvg-Loss: 0.5275\tTraining Accuracy : 0.8022\n",
            "Epoch: 7\tBatch: 600\tAvg-Loss: 0.4998\tTraining Accuracy : 0.8116\n",
            "Epoch: 7\tBatch: 650\tAvg-Loss: 0.5323\tTraining Accuracy : 0.8009\n",
            "Epoch: 7\tBatch: 700\tAvg-Loss: 0.4861\tTraining Accuracy : 0.8184\n",
            "Epoch: 7\tBatch: 750\tAvg-Loss: 0.4666\tTraining Accuracy : 0.8291\n",
            "Epoch: 7\tBatch: 800\tAvg-Loss: 0.5143\tTraining Accuracy : 0.8084\n",
            "Epoch: 7\tBatch: 850\tAvg-Loss: 0.4886\tTraining Accuracy : 0.8213\n",
            "Epoch: 7\tBatch: 900\tAvg-Loss: 0.5128\tTraining Accuracy : 0.8019\n",
            "Epoch: 7\tBatch: 950\tAvg-Loss: 0.4748\tTraining Accuracy : 0.8250\n",
            "Epoch: 7\tBatch: 1000\tAvg-Loss: 0.4741\tTraining Accuracy : 0.8300\n",
            "Epoch: 7\tBatch: 1050\tAvg-Loss: 0.4761\tTraining Accuracy : 0.8219\n",
            "Epoch: 7\tBatch: 1100\tAvg-Loss: 0.5071\tTraining Accuracy : 0.8106\n",
            "Epoch: 7\tBatch: 1150\tAvg-Loss: 0.4776\tTraining Accuracy : 0.8184\n",
            "Epoch: 7\tBatch: 1200\tAvg-Loss: 0.4861\tTraining Accuracy : 0.8163\n",
            "Epoch: 7\tBatch: 1250\tAvg-Loss: 0.5058\tTraining Accuracy : 0.8269\n",
            "Epoch: 7\tBatch: 1300\tAvg-Loss: 0.5369\tTraining Accuracy : 0.7978\n",
            "Epoch: 7, Validation Loss: 8.885, Validation Accuracy: 0.075\n",
            "Epoch: 8\tBatch: 50\tAvg-Loss: 0.4835\tTraining Accuracy : 0.8184\n",
            "Epoch: 8\tBatch: 100\tAvg-Loss: 0.4811\tTraining Accuracy : 0.8241\n",
            "Epoch: 8\tBatch: 150\tAvg-Loss: 0.4585\tTraining Accuracy : 0.8387\n",
            "Epoch: 8\tBatch: 200\tAvg-Loss: 0.4806\tTraining Accuracy : 0.8241\n",
            "Epoch: 8\tBatch: 250\tAvg-Loss: 0.4728\tTraining Accuracy : 0.8222\n",
            "Epoch: 8\tBatch: 300\tAvg-Loss: 0.4664\tTraining Accuracy : 0.8250\n",
            "Epoch: 8\tBatch: 350\tAvg-Loss: 0.4462\tTraining Accuracy : 0.8400\n",
            "Epoch: 8\tBatch: 400\tAvg-Loss: 0.4333\tTraining Accuracy : 0.8447\n",
            "Epoch: 8\tBatch: 450\tAvg-Loss: 0.4149\tTraining Accuracy : 0.8453\n",
            "Epoch: 8\tBatch: 500\tAvg-Loss: 0.4709\tTraining Accuracy : 0.8278\n",
            "Epoch: 8\tBatch: 550\tAvg-Loss: 0.4452\tTraining Accuracy : 0.8334\n",
            "Epoch: 8\tBatch: 600\tAvg-Loss: 0.4844\tTraining Accuracy : 0.8209\n",
            "Epoch: 8\tBatch: 650\tAvg-Loss: 0.4479\tTraining Accuracy : 0.8344\n",
            "Epoch: 8\tBatch: 700\tAvg-Loss: 0.5078\tTraining Accuracy : 0.8119\n",
            "Epoch: 8\tBatch: 750\tAvg-Loss: 0.4384\tTraining Accuracy : 0.8325\n",
            "Epoch: 8\tBatch: 800\tAvg-Loss: 0.4321\tTraining Accuracy : 0.8403\n",
            "Epoch: 8\tBatch: 850\tAvg-Loss: 0.4544\tTraining Accuracy : 0.8325\n",
            "Epoch: 8\tBatch: 900\tAvg-Loss: 0.4490\tTraining Accuracy : 0.8291\n",
            "Epoch: 8\tBatch: 950\tAvg-Loss: 0.4867\tTraining Accuracy : 0.8291\n",
            "Epoch: 8\tBatch: 1000\tAvg-Loss: 0.4687\tTraining Accuracy : 0.8203\n",
            "Epoch: 8\tBatch: 1050\tAvg-Loss: 0.4946\tTraining Accuracy : 0.8153\n",
            "Epoch: 8\tBatch: 1100\tAvg-Loss: 0.4785\tTraining Accuracy : 0.8269\n",
            "Epoch: 8\tBatch: 1150\tAvg-Loss: 0.4138\tTraining Accuracy : 0.8406\n",
            "Epoch: 8\tBatch: 1200\tAvg-Loss: 0.4463\tTraining Accuracy : 0.8237\n",
            "Epoch: 8\tBatch: 1250\tAvg-Loss: 0.4364\tTraining Accuracy : 0.8375\n",
            "Epoch: 8\tBatch: 1300\tAvg-Loss: 0.4482\tTraining Accuracy : 0.8347\n",
            "Epoch     9: reducing learning rate of group 0 to 4.9000e-02.\n",
            "Epoch: 8, Validation Loss: 8.291, Validation Accuracy: 0.078\n",
            "Epoch: 9\tBatch: 50\tAvg-Loss: 0.3570\tTraining Accuracy : 0.8638\n",
            "Epoch: 9\tBatch: 100\tAvg-Loss: 0.3235\tTraining Accuracy : 0.8719\n",
            "Epoch: 9\tBatch: 150\tAvg-Loss: 0.2869\tTraining Accuracy : 0.8888\n",
            "Epoch: 9\tBatch: 200\tAvg-Loss: 0.3069\tTraining Accuracy : 0.8678\n",
            "Epoch: 9\tBatch: 250\tAvg-Loss: 0.2908\tTraining Accuracy : 0.8862\n",
            "Epoch: 9\tBatch: 300\tAvg-Loss: 0.3033\tTraining Accuracy : 0.8797\n",
            "Epoch: 9\tBatch: 350\tAvg-Loss: 0.3039\tTraining Accuracy : 0.8828\n",
            "Epoch: 9\tBatch: 400\tAvg-Loss: 0.2744\tTraining Accuracy : 0.9012\n",
            "Epoch: 9\tBatch: 450\tAvg-Loss: 0.2757\tTraining Accuracy : 0.8894\n",
            "Epoch: 9\tBatch: 500\tAvg-Loss: 0.2614\tTraining Accuracy : 0.8972\n",
            "Epoch: 9\tBatch: 550\tAvg-Loss: 0.2978\tTraining Accuracy : 0.8900\n",
            "Epoch: 9\tBatch: 600\tAvg-Loss: 0.3024\tTraining Accuracy : 0.8891\n",
            "Epoch: 9\tBatch: 650\tAvg-Loss: 0.2855\tTraining Accuracy : 0.8881\n",
            "Epoch: 9\tBatch: 700\tAvg-Loss: 0.2893\tTraining Accuracy : 0.8900\n",
            "Epoch: 9\tBatch: 750\tAvg-Loss: 0.2724\tTraining Accuracy : 0.8966\n",
            "Epoch: 9\tBatch: 800\tAvg-Loss: 0.2730\tTraining Accuracy : 0.8994\n",
            "Epoch: 9\tBatch: 850\tAvg-Loss: 0.2880\tTraining Accuracy : 0.8922\n",
            "Epoch: 9\tBatch: 900\tAvg-Loss: 0.2812\tTraining Accuracy : 0.8956\n",
            "Epoch: 9\tBatch: 950\tAvg-Loss: 0.2800\tTraining Accuracy : 0.8912\n",
            "Epoch: 9\tBatch: 1000\tAvg-Loss: 0.2888\tTraining Accuracy : 0.8859\n",
            "Epoch: 9\tBatch: 1050\tAvg-Loss: 0.2665\tTraining Accuracy : 0.8922\n",
            "Epoch: 9\tBatch: 1100\tAvg-Loss: 0.2919\tTraining Accuracy : 0.8900\n",
            "Epoch: 9\tBatch: 1150\tAvg-Loss: 0.2845\tTraining Accuracy : 0.8969\n",
            "Epoch: 9\tBatch: 1200\tAvg-Loss: 0.2687\tTraining Accuracy : 0.8981\n",
            "Epoch: 9\tBatch: 1250\tAvg-Loss: 0.2315\tTraining Accuracy : 0.9050\n",
            "Epoch: 9\tBatch: 1300\tAvg-Loss: 0.2739\tTraining Accuracy : 0.8947\n",
            "Epoch: 9, Validation Loss: 11.517, Validation Accuracy: 0.074\n",
            "Epoch: 10\tBatch: 50\tAvg-Loss: 0.2634\tTraining Accuracy : 0.9012\n",
            "Epoch: 10\tBatch: 100\tAvg-Loss: 0.2533\tTraining Accuracy : 0.9062\n",
            "Epoch: 10\tBatch: 150\tAvg-Loss: 0.2485\tTraining Accuracy : 0.9041\n",
            "Epoch: 10\tBatch: 200\tAvg-Loss: 0.2597\tTraining Accuracy : 0.8966\n",
            "Epoch: 10\tBatch: 250\tAvg-Loss: 0.2314\tTraining Accuracy : 0.9084\n",
            "Epoch: 10\tBatch: 300\tAvg-Loss: 0.2342\tTraining Accuracy : 0.9072\n",
            "Epoch: 10\tBatch: 350\tAvg-Loss: 0.2668\tTraining Accuracy : 0.8916\n",
            "Epoch: 10\tBatch: 400\tAvg-Loss: 0.2850\tTraining Accuracy : 0.8947\n",
            "Epoch: 10\tBatch: 450\tAvg-Loss: 0.2877\tTraining Accuracy : 0.8966\n",
            "Epoch: 10\tBatch: 500\tAvg-Loss: 0.2653\tTraining Accuracy : 0.8984\n",
            "Epoch: 10\tBatch: 550\tAvg-Loss: 0.2545\tTraining Accuracy : 0.9028\n",
            "Epoch: 10\tBatch: 600\tAvg-Loss: 0.2418\tTraining Accuracy : 0.9041\n",
            "Epoch: 10\tBatch: 650\tAvg-Loss: 0.2820\tTraining Accuracy : 0.8906\n",
            "Epoch: 10\tBatch: 700\tAvg-Loss: 0.2687\tTraining Accuracy : 0.8962\n",
            "Epoch: 10\tBatch: 750\tAvg-Loss: 0.2559\tTraining Accuracy : 0.8991\n",
            "Epoch: 10\tBatch: 800\tAvg-Loss: 0.2833\tTraining Accuracy : 0.8966\n",
            "Epoch: 10\tBatch: 850\tAvg-Loss: 0.2611\tTraining Accuracy : 0.9006\n",
            "Epoch: 10\tBatch: 900\tAvg-Loss: 0.2609\tTraining Accuracy : 0.8969\n",
            "Epoch: 10\tBatch: 950\tAvg-Loss: 0.2680\tTraining Accuracy : 0.8953\n",
            "Epoch: 10\tBatch: 1000\tAvg-Loss: 0.2659\tTraining Accuracy : 0.8959\n",
            "Epoch: 10\tBatch: 1050\tAvg-Loss: 0.2494\tTraining Accuracy : 0.8997\n",
            "Epoch: 10\tBatch: 1100\tAvg-Loss: 0.2549\tTraining Accuracy : 0.8984\n",
            "Epoch: 10\tBatch: 1150\tAvg-Loss: 0.2610\tTraining Accuracy : 0.8962\n",
            "Epoch: 10\tBatch: 1200\tAvg-Loss: 0.2993\tTraining Accuracy : 0.8850\n",
            "Epoch: 10\tBatch: 1250\tAvg-Loss: 0.2733\tTraining Accuracy : 0.8969\n",
            "Epoch: 10\tBatch: 1300\tAvg-Loss: 0.2428\tTraining Accuracy : 0.9103\n",
            "Epoch: 10, Validation Loss: 10.510, Validation Accuracy: 0.082\n",
            "Epoch: 11\tBatch: 50\tAvg-Loss: 0.2519\tTraining Accuracy : 0.9025\n",
            "Epoch: 11\tBatch: 100\tAvg-Loss: 0.2532\tTraining Accuracy : 0.9022\n",
            "Epoch: 11\tBatch: 150\tAvg-Loss: 0.2567\tTraining Accuracy : 0.9016\n",
            "Epoch: 11\tBatch: 200\tAvg-Loss: 0.2441\tTraining Accuracy : 0.9062\n",
            "Epoch: 11\tBatch: 250\tAvg-Loss: 0.2637\tTraining Accuracy : 0.9041\n",
            "Epoch: 11\tBatch: 300\tAvg-Loss: 0.2862\tTraining Accuracy : 0.8938\n",
            "Epoch: 11\tBatch: 350\tAvg-Loss: 0.2535\tTraining Accuracy : 0.9056\n",
            "Epoch: 11\tBatch: 400\tAvg-Loss: 0.2440\tTraining Accuracy : 0.9041\n",
            "Epoch: 11\tBatch: 450\tAvg-Loss: 0.2320\tTraining Accuracy : 0.9084\n",
            "Epoch: 11\tBatch: 500\tAvg-Loss: 0.2579\tTraining Accuracy : 0.9034\n",
            "Epoch: 11\tBatch: 550\tAvg-Loss: 0.2342\tTraining Accuracy : 0.9050\n",
            "Epoch: 11\tBatch: 600\tAvg-Loss: 0.2456\tTraining Accuracy : 0.9056\n",
            "Epoch: 11\tBatch: 650\tAvg-Loss: 0.2375\tTraining Accuracy : 0.9163\n",
            "Epoch: 11\tBatch: 700\tAvg-Loss: 0.2685\tTraining Accuracy : 0.8950\n",
            "Epoch: 11\tBatch: 750\tAvg-Loss: 0.2566\tTraining Accuracy : 0.9053\n",
            "Epoch: 11\tBatch: 800\tAvg-Loss: 0.2354\tTraining Accuracy : 0.9044\n",
            "Epoch: 11\tBatch: 850\tAvg-Loss: 0.2768\tTraining Accuracy : 0.8922\n",
            "Epoch: 11\tBatch: 900\tAvg-Loss: 0.2444\tTraining Accuracy : 0.9131\n",
            "Epoch: 11\tBatch: 950\tAvg-Loss: 0.2600\tTraining Accuracy : 0.8981\n",
            "Epoch: 11\tBatch: 1000\tAvg-Loss: 0.2561\tTraining Accuracy : 0.9025\n",
            "Epoch: 11\tBatch: 1050\tAvg-Loss: 0.2629\tTraining Accuracy : 0.8966\n",
            "Epoch: 11\tBatch: 1100\tAvg-Loss: 0.2537\tTraining Accuracy : 0.8944\n",
            "Epoch: 11\tBatch: 1150\tAvg-Loss: 0.2833\tTraining Accuracy : 0.8972\n",
            "Epoch: 11\tBatch: 1200\tAvg-Loss: 0.2707\tTraining Accuracy : 0.8906\n",
            "Epoch: 11\tBatch: 1250\tAvg-Loss: 0.2451\tTraining Accuracy : 0.9087\n",
            "Epoch: 11\tBatch: 1300\tAvg-Loss: 0.2809\tTraining Accuracy : 0.8916\n",
            "Epoch: 11, Validation Loss: 10.937, Validation Accuracy: 0.080\n",
            "Epoch: 12\tBatch: 50\tAvg-Loss: 0.2162\tTraining Accuracy : 0.9163\n",
            "Epoch: 12\tBatch: 100\tAvg-Loss: 0.2321\tTraining Accuracy : 0.9041\n",
            "Epoch: 12\tBatch: 150\tAvg-Loss: 0.2163\tTraining Accuracy : 0.9191\n",
            "Epoch: 12\tBatch: 200\tAvg-Loss: 0.2313\tTraining Accuracy : 0.9078\n",
            "Epoch: 12\tBatch: 250\tAvg-Loss: 0.2676\tTraining Accuracy : 0.9044\n",
            "Epoch: 12\tBatch: 300\tAvg-Loss: 0.2346\tTraining Accuracy : 0.9103\n",
            "Epoch: 12\tBatch: 350\tAvg-Loss: 0.2749\tTraining Accuracy : 0.8925\n",
            "Epoch: 12\tBatch: 400\tAvg-Loss: 0.2668\tTraining Accuracy : 0.9050\n",
            "Epoch: 12\tBatch: 450\tAvg-Loss: 0.2495\tTraining Accuracy : 0.9056\n",
            "Epoch: 12\tBatch: 500\tAvg-Loss: 0.2706\tTraining Accuracy : 0.8872\n",
            "Epoch: 12\tBatch: 550\tAvg-Loss: 0.2654\tTraining Accuracy : 0.8969\n",
            "Epoch: 12\tBatch: 600\tAvg-Loss: 0.2440\tTraining Accuracy : 0.9062\n",
            "Epoch: 12\tBatch: 650\tAvg-Loss: 0.2392\tTraining Accuracy : 0.9103\n",
            "Epoch: 12\tBatch: 700\tAvg-Loss: 0.2449\tTraining Accuracy : 0.9150\n",
            "Epoch: 12\tBatch: 750\tAvg-Loss: 0.2714\tTraining Accuracy : 0.8931\n",
            "Epoch: 12\tBatch: 800\tAvg-Loss: 0.2572\tTraining Accuracy : 0.9000\n",
            "Epoch: 12\tBatch: 850\tAvg-Loss: 0.2180\tTraining Accuracy : 0.9187\n",
            "Epoch: 12\tBatch: 900\tAvg-Loss: 0.2334\tTraining Accuracy : 0.9087\n",
            "Epoch: 12\tBatch: 950\tAvg-Loss: 0.2714\tTraining Accuracy : 0.8969\n",
            "Epoch: 12\tBatch: 1000\tAvg-Loss: 0.2455\tTraining Accuracy : 0.9016\n",
            "Epoch: 12\tBatch: 1050\tAvg-Loss: 0.2565\tTraining Accuracy : 0.9019\n",
            "Epoch: 12\tBatch: 1100\tAvg-Loss: 0.2642\tTraining Accuracy : 0.8953\n",
            "Epoch: 12\tBatch: 1150\tAvg-Loss: 0.2512\tTraining Accuracy : 0.9019\n",
            "Epoch: 12\tBatch: 1200\tAvg-Loss: 0.2602\tTraining Accuracy : 0.9000\n",
            "Epoch: 12\tBatch: 1250\tAvg-Loss: 0.2564\tTraining Accuracy : 0.9003\n",
            "Epoch: 12\tBatch: 1300\tAvg-Loss: 0.2609\tTraining Accuracy : 0.9019\n",
            "Epoch    13: reducing learning rate of group 0 to 3.4300e-02.\n",
            "Epoch: 12, Validation Loss: 11.150, Validation Accuracy: 0.078\n",
            "Epoch: 13\tBatch: 50\tAvg-Loss: 0.2025\tTraining Accuracy : 0.9187\n",
            "Epoch: 13\tBatch: 100\tAvg-Loss: 0.1916\tTraining Accuracy : 0.9259\n",
            "Epoch: 13\tBatch: 150\tAvg-Loss: 0.1874\tTraining Accuracy : 0.9237\n",
            "Epoch: 13\tBatch: 200\tAvg-Loss: 0.2006\tTraining Accuracy : 0.9219\n",
            "Epoch: 13\tBatch: 250\tAvg-Loss: 0.1733\tTraining Accuracy : 0.9266\n",
            "Epoch: 13\tBatch: 300\tAvg-Loss: 0.1781\tTraining Accuracy : 0.9303\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-208c49320114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m                   \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                   \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                   nesterov=nesterov)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vIdH8nTXpno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee8b42f-f705-49d2-b25c-e09a93c75638"
      },
      "source": [
        "# Test\n",
        "\n",
        "network.load_state_dict(torch.load(\"/content/gdrive/MyDrive/baseline_12channels/best_model.pt\"))\n",
        "\n",
        "with torch.no_grad():\n",
        "  network.eval()\n",
        "  num_correct = 0\n",
        "  for batch_num, (x, y) in enumerate(test_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    outputs = network(x)\n",
        "    num_correct += (torch.argmax(outputs, axis=1) == y).sum().item()\n",
        "\n",
        "test_acc = num_correct / len(test_set)\n",
        "print(test_acc)\n"
      ],
      "id": "6vIdH8nTXpno",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.046804032347402234\n"
          ]
        }
      ]
    }
  ]
}