{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Baseline_approach_Resnet34_6channels_direct.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7badc3cb"
      },
      "source": [
        "## 1. Libraries and Setup"
      ],
      "id": "7badc3cb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuO32Xm2fb1z",
        "outputId": "79acea15-13d3-462f-fbc0-08d420d91544"
      },
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "AuO32Xm2fb1z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIlv-QiNgNt7"
      },
      "source": [
        "!cp /content/gdrive/MyDrive/converted_224x224.tar.gz /content\n",
        "%cd /content\n",
        "!tar -xvzf converted_224x224.tar.gz"
      ],
      "id": "jIlv-QiNgNt7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2AK4w8Nh-4Q"
      },
      "source": [
        "!ls converted_224x224/"
      ],
      "id": "a2AK4w8Nh-4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "812ec14e"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pdb\n",
        "import gc\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "id": "812ec14e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5972057",
        "outputId": "d8ec675d-912d-4f6f-b69e-b37c83e874d5"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "num_workers = 8 if cuda else 0\n",
        "\n",
        "print(\"Cuda = \", str(cuda), \" with num_workers = \", str(num_workers),  \" system version = \", sys.version)"
      ],
      "id": "c5972057",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda =  True  with num_workers =  8  system version =  3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e71e53e8"
      },
      "source": [
        "## 2. Data Loading"
      ],
      "id": "e71e53e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bdee1e8"
      },
      "source": [
        "### 2.1 Load Data"
      ],
      "id": "3bdee1e8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e874ee1"
      },
      "source": [
        "np.random.seed(0)\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/dataset/1+1.csv\")\n",
        "df = df.iloc[:, 1:]\n",
        "\n",
        "train_end = int(len(df)*0.7)\n",
        "val_end = int(len(df)*0.85)\n",
        "train_data = df[:train_end]\n",
        "val_data = df[train_end:val_end]\n",
        "test_data = df[val_end:]"
      ],
      "id": "6e874ee1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e669450b"
      },
      "source": [
        "train_data = train_data.reset_index().drop('Unnamed: 0.1',1).drop('index',1)\n",
        "val_data = val_data.reset_index().drop('Unnamed: 0.1',1).drop('index',1)\n",
        "test_data = test_data.reset_index().drop('Unnamed: 0.1',1).drop('index',1)"
      ],
      "id": "e669450b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "1gs_EeHEuiP7",
        "outputId": "b1eb7790-3251-497c-8a76-df62156bed7e"
      },
      "source": [
        "test_data"
      ],
      "id": "1gs_EeHEuiP7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frames</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>('frame_149840.jpg', 'frame_151422.jpg')</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>('frame_151595.jpg', 'frame_149880.jpg')</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>('frame_151667.jpg', 'frame_149876.jpg')</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>('frame_149876.jpg', 'frame_151705.jpg')</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>('frame_149852.jpg', 'frame_151768.jpg')</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18141</th>\n",
              "      <td>('frame_174615.jpg', 'frame_180809.jpg')</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18142</th>\n",
              "      <td>('frame_180855.jpg', 'frame_174653.jpg')</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18143</th>\n",
              "      <td>('frame_180890.jpg', 'frame_174594.jpg')</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18144</th>\n",
              "      <td>('frame_181123.jpg', 'frame_174612.jpg')</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18145</th>\n",
              "      <td>('frame_174574.jpg', 'frame_181333.jpg')</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18146 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         frames  label\n",
              "0      ('frame_149840.jpg', 'frame_151422.jpg')      0\n",
              "1      ('frame_151595.jpg', 'frame_149880.jpg')      1\n",
              "2      ('frame_151667.jpg', 'frame_149876.jpg')      1\n",
              "3      ('frame_149876.jpg', 'frame_151705.jpg')      0\n",
              "4      ('frame_149852.jpg', 'frame_151768.jpg')      0\n",
              "...                                         ...    ...\n",
              "18141  ('frame_174615.jpg', 'frame_180809.jpg')      0\n",
              "18142  ('frame_180855.jpg', 'frame_174653.jpg')      1\n",
              "18143  ('frame_180890.jpg', 'frame_174594.jpg')      1\n",
              "18144  ('frame_181123.jpg', 'frame_174612.jpg')      1\n",
              "18145  ('frame_174574.jpg', 'frame_181333.jpg')      0\n",
              "\n",
              "[18146 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15cbf79"
      },
      "source": [
        "### 2.2 Custom Dataset Class"
      ],
      "id": "f15cbf79"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK6gHTVopf7M"
      },
      "source": [
        "# cur_dir = \"data/qscale31_unique/\"\n",
        "cur_dir = \"converted_224x224/\""
      ],
      "id": "RK6gHTVopf7M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21554c7"
      },
      "source": [
        "# Define dataset class\n",
        "class MyDataSet(Dataset):\n",
        "\n",
        "    # load the dataset\n",
        "    def __init__(self, data, **kwargs):\n",
        "        self.X = data[\"frames\"]\n",
        "        self.Y = data[\"label\"]\n",
        "\n",
        "    # get number of items/rows in dataset\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.X[index], self.Y[index]\n",
        "        for c in [\"(\",\")\",\",\",\"'\"]:\n",
        "            x = x.replace(c, \"\")\n",
        "        x = x.split(\" \")\n",
        "        images = []\n",
        "        for img_file in x:\n",
        "            img = Image.open(cur_dir + img_file)\n",
        "            img = torchvision.transforms.ToTensor()(img)\n",
        "            images.extend(img)\n",
        "        x = torch.stack(images)\n",
        "        return x, y\n",
        "    "
      ],
      "id": "c21554c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tpf6FW9nr7J",
        "outputId": "fb142ab0-0e92-4da2-e370-6dbd70a23eba"
      },
      "source": [
        "train_set = MyDataSet(train_data)\n",
        "train_set[0][0].shape"
      ],
      "id": "3Tpf6FW9nr7J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d6b5efe"
      },
      "source": [
        "### 2.3 Dataloader"
      ],
      "id": "6d6b5efe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fb2a207"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# training data\n",
        "train_set = MyDataSet(train_data)\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=8)\n",
        "\n",
        "# validation data\n",
        "val_set = MyDataSet(val_data)\n",
        "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size, num_workers=8)\n",
        "\n",
        "# test data\n",
        "test_set = MyDataSet(test_data)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size, num_workers=8)"
      ],
      "id": "4fb2a207",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a589effb"
      },
      "source": [
        "## 3. Model"
      ],
      "id": "a589effb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c94574d"
      },
      "source": [
        "# This is the simplest possible residual block, with only one CNN layer.\n",
        "# Looking at the paper, you can extend this block to have more layers, bottleneck, grouped convs (from shufflenet), etc.\n",
        "# Or even look at more recent papers like resnext, regnet, resnest, senet, etc.\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel,stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False, dilation = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu1 = nn.ReLU(inplace = True)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding= 1, bias=False, dilation = 1)\n",
        "        self.bn2 =  nn.BatchNorm2d(out_channel)\n",
        "        if stride == 1:\n",
        "            self.shortcut = nn.Identity()\n",
        "        else:\n",
        "            self.shortcut = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride)\n",
        "        self.relu2 = nn.ReLU(inplace = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        shortcut = self.shortcut(x) \n",
        "        out = self.relu2(out + shortcut)\n",
        "        \n",
        "        return out"
      ],
      "id": "7c94574d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8386991f"
      },
      "source": [
        "# This has hard-coded hidden feature sizes.\n",
        "# You can extend this to take in a list of hidden sizes as argument if you want.\n",
        "class ClassificationNetwork(nn.Module):\n",
        "    def __init__(self, in_features, num_classes,feat_dim = 512):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_features, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,128,stride = 2),\n",
        "            ResidualBlock(128,128),\n",
        "            ResidualBlock(128,128),\n",
        "            ResidualBlock(128,128),\n",
        "            ResidualBlock(128,256,stride = 2),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,256),\n",
        "            ResidualBlock(256,512,stride = 2),\n",
        "            ResidualBlock(512,512),\n",
        "            ResidualBlock(512,512),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), # For each channel, collapses (averages) the entire feature map (height & width) to 1x1\n",
        "            nn.Flatten(1), # the above ends up with batch_size x 512 x 1 x 1, flatten to batch_size x 512\n",
        "        )\n",
        "        self.linear_emb = nn.Linear(512, feat_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.linear_output_1 = nn.Linear(512,512)\n",
        "        self.relu_output = nn.ReLU(inplace=True)\n",
        "        self.dropout_output = nn.Dropout(p=0.4)\n",
        "        self.linear_output_2 = nn.Linear(512,num_classes)\n",
        "        # self.fc = nn.Linear(512,num_classes)\n",
        "        \n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          elif isinstance(m, (nn.BatchNorm2d)):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0) \n",
        "\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, ResidualBlock):\n",
        "            nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]  \n",
        "\n",
        "    def forward(self, x, return_embedding=False):\n",
        "        embedding = self.layers(x)\n",
        "        embedding_out = self.linear_emb(embedding)\n",
        "        embedding_out = self.relu(embedding_out)\n",
        "\n",
        "        output = self.linear_output_1(embedding)\n",
        "        output = self.relu_output(output)\n",
        "        output = self.dropout_output(output)\n",
        "        output = self.linear_output_2(output)\n",
        "        # output = self.fc(embedding)\n",
        "\n",
        "        if return_embedding:\n",
        "            return embedding_out,output\n",
        "        else:\n",
        "            return output "
      ],
      "id": "8386991f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9kNdjdnvVgk"
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, in_channels, embedding, num_images, num_classes):\n",
        "        super().__init__()\n",
        "        self.cnn = ClassificationNetwork(in_channels, embedding)\n",
        "        self.mlp = nn.Sequential(nn.Linear(embedding*num_images, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = x[:, 0:3, :, :]\n",
        "      x2 = x[:, 3:6, :, :]\n",
        "\n",
        "      out1 = self.cnn(x1)\n",
        "      out2 = self.cnn(x2)\n",
        "\n",
        "      out = torch.cat([out1, out2], axis=1)\n",
        "      logits = self.mlp(out)\n",
        "      return logits"
      ],
      "id": "y9kNdjdnvVgk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "964a4c9e"
      },
      "source": [
        "numEpochs = 500\n",
        "in_features = 3 # TODO: change RGB channels according to num of frames\n",
        "embedding = 128\n",
        "\n",
        "learningRate = 0.1\n",
        "weightDecay = 1e-4\n",
        "\n",
        "num_images = 2\n",
        "num_classes = 2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "network = Network(in_features, embedding, num_images, num_classes)\n",
        "#network.load_state_dict(torch.load(\"model_checkpoints/resnet34/lr_0.1-2/model_2.pt\"))\n",
        "network = network.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.7, verbose=True)"
      ],
      "id": "964a4c9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7b85b7de",
        "outputId": "6c6d8c26-7f30-40f0-bd6a-31b8c9211ffc"
      },
      "source": [
        "# Train!\n",
        "max_val_acc = 0\n",
        "for epoch in range(numEpochs):\n",
        "    # Train\n",
        "    network.train()\n",
        "    avg_loss = 0.0\n",
        "    avg_train_acc = 0.0\n",
        "    for batch_num, (x, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = network(x)\n",
        "        num_train_correct = (torch.argmax(outputs, axis=1) == y).sum().item()\n",
        "        num_labels = len(y)\n",
        "        avg_train_acc += (num_train_correct/num_labels)\n",
        "\n",
        "        loss = criterion(outputs, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "        if batch_num % 50 == 49:\n",
        "            print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}\\tTraining Accuracy : {:.4f}'.format(epoch, batch_num+1, avg_loss/50, avg_train_acc/50))\n",
        "            avg_loss = 0.0\n",
        "            avg_train_acc = 0.0\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        del x\n",
        "        del y\n",
        "        del loss\n",
        "    \n",
        "    # Validate\n",
        "    with torch.no_grad():\n",
        "        network.eval()\n",
        "        avg_val_loss = 0.0\n",
        "        num_correct = 0\n",
        "        for batch_num, (x, y) in enumerate(val_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = network(x)\n",
        "            num_correct += (torch.argmax(outputs, axis=1) == y).sum().item()\n",
        "            loss = criterion(outputs, y.long())\n",
        "            avg_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = avg_val_loss / len(val_loader)\n",
        "        val_acc = num_correct / len(val_set)\n",
        "        checkpoint_name = \"/content/gdrive/MyDrive/baseline_6channels/model_\" + str(epoch) + \".pt\"\n",
        "        torch.save(network.state_dict(), checkpoint_name)\n",
        "        if val_acc > max_val_acc:\n",
        "            max_val_acc = val_acc\n",
        "            torch.save(network.state_dict(), \"/content/gdrive/MyDrive/baseline_6channels/best_model.pt\")\n",
        "    \n",
        "    scheduler.step(avg_val_loss)\n",
        "    print('Epoch: {}, Validation Loss: {:.3f}, Validation Accuracy: {:.3f}'.format(epoch, avg_val_loss, val_acc))"
      ],
      "id": "7b85b7de",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\tBatch: 50\tAvg-Loss: 0.6964\tTraining Accuracy : 0.5055\n",
            "Epoch: 0\tBatch: 100\tAvg-Loss: 0.6940\tTraining Accuracy : 0.5130\n",
            "Epoch: 0\tBatch: 150\tAvg-Loss: 0.6942\tTraining Accuracy : 0.5003\n",
            "Epoch: 0\tBatch: 200\tAvg-Loss: 0.6940\tTraining Accuracy : 0.5016\n",
            "Epoch: 0\tBatch: 250\tAvg-Loss: 0.6938\tTraining Accuracy : 0.5041\n",
            "Epoch: 0\tBatch: 300\tAvg-Loss: 0.6927\tTraining Accuracy : 0.5112\n",
            "Epoch: 0\tBatch: 350\tAvg-Loss: 0.6925\tTraining Accuracy : 0.5209\n",
            "Epoch: 0\tBatch: 400\tAvg-Loss: 0.6920\tTraining Accuracy : 0.5189\n",
            "Epoch: 0\tBatch: 450\tAvg-Loss: 0.6917\tTraining Accuracy : 0.5198\n",
            "Epoch: 0\tBatch: 500\tAvg-Loss: 0.6911\tTraining Accuracy : 0.5244\n",
            "Epoch: 0\tBatch: 550\tAvg-Loss: 0.6923\tTraining Accuracy : 0.5214\n",
            "Epoch: 0\tBatch: 600\tAvg-Loss: 0.6950\tTraining Accuracy : 0.5145\n",
            "Epoch: 0\tBatch: 650\tAvg-Loss: 0.6945\tTraining Accuracy : 0.4978\n",
            "Epoch: 0, Validation Loss: 0.687, Validation Accuracy: 0.543\n",
            "Epoch: 1\tBatch: 50\tAvg-Loss: 0.6917\tTraining Accuracy : 0.5241\n",
            "Epoch: 1\tBatch: 100\tAvg-Loss: 0.6926\tTraining Accuracy : 0.5205\n",
            "Epoch: 1\tBatch: 150\tAvg-Loss: 0.6921\tTraining Accuracy : 0.5144\n",
            "Epoch: 1\tBatch: 200\tAvg-Loss: 0.6920\tTraining Accuracy : 0.5255\n",
            "Epoch: 1\tBatch: 250\tAvg-Loss: 0.6925\tTraining Accuracy : 0.5134\n",
            "Epoch: 1\tBatch: 300\tAvg-Loss: 0.6896\tTraining Accuracy : 0.5369\n",
            "Epoch: 1\tBatch: 350\tAvg-Loss: 0.6918\tTraining Accuracy : 0.5234\n",
            "Epoch: 1\tBatch: 400\tAvg-Loss: 0.6889\tTraining Accuracy : 0.5414\n",
            "Epoch: 1\tBatch: 450\tAvg-Loss: 0.6913\tTraining Accuracy : 0.5306\n",
            "Epoch: 1\tBatch: 500\tAvg-Loss: 0.6907\tTraining Accuracy : 0.5220\n",
            "Epoch: 1\tBatch: 550\tAvg-Loss: 0.6890\tTraining Accuracy : 0.5372\n",
            "Epoch: 1\tBatch: 600\tAvg-Loss: 0.6809\tTraining Accuracy : 0.5663\n",
            "Epoch: 1\tBatch: 650\tAvg-Loss: 0.6766\tTraining Accuracy : 0.5611\n",
            "Epoch: 1, Validation Loss: 0.745, Validation Accuracy: 0.495\n",
            "Epoch: 2\tBatch: 50\tAvg-Loss: 0.6530\tTraining Accuracy : 0.6055\n",
            "Epoch: 2\tBatch: 100\tAvg-Loss: 0.6364\tTraining Accuracy : 0.6311\n",
            "Epoch: 2\tBatch: 150\tAvg-Loss: 0.6001\tTraining Accuracy : 0.6714\n",
            "Epoch: 2\tBatch: 200\tAvg-Loss: 0.5480\tTraining Accuracy : 0.7152\n",
            "Epoch: 2\tBatch: 250\tAvg-Loss: 0.5298\tTraining Accuracy : 0.7277\n",
            "Epoch: 2\tBatch: 300\tAvg-Loss: 0.5016\tTraining Accuracy : 0.7462\n",
            "Epoch: 2\tBatch: 350\tAvg-Loss: 0.4364\tTraining Accuracy : 0.7905\n",
            "Epoch: 2\tBatch: 400\tAvg-Loss: 0.4214\tTraining Accuracy : 0.8008\n",
            "Epoch: 2\tBatch: 450\tAvg-Loss: 0.3850\tTraining Accuracy : 0.8266\n",
            "Epoch: 2\tBatch: 500\tAvg-Loss: 0.3466\tTraining Accuracy : 0.8448\n",
            "Epoch: 2\tBatch: 550\tAvg-Loss: 0.3431\tTraining Accuracy : 0.8428\n",
            "Epoch: 2\tBatch: 600\tAvg-Loss: 0.3179\tTraining Accuracy : 0.8525\n",
            "Epoch: 2\tBatch: 650\tAvg-Loss: 0.3031\tTraining Accuracy : 0.8673\n",
            "Epoch: 2, Validation Loss: 1.360, Validation Accuracy: 0.545\n",
            "Epoch: 3\tBatch: 50\tAvg-Loss: 0.2642\tTraining Accuracy : 0.8875\n",
            "Epoch: 3\tBatch: 100\tAvg-Loss: 0.2624\tTraining Accuracy : 0.8858\n",
            "Epoch: 3\tBatch: 150\tAvg-Loss: 0.2369\tTraining Accuracy : 0.8992\n",
            "Epoch: 3\tBatch: 200\tAvg-Loss: 0.2382\tTraining Accuracy : 0.9011\n",
            "Epoch: 3\tBatch: 250\tAvg-Loss: 0.2218\tTraining Accuracy : 0.9056\n",
            "Epoch: 3\tBatch: 300\tAvg-Loss: 0.2197\tTraining Accuracy : 0.9078\n",
            "Epoch: 3\tBatch: 350\tAvg-Loss: 0.2162\tTraining Accuracy : 0.9050\n",
            "Epoch: 3\tBatch: 400\tAvg-Loss: 0.1958\tTraining Accuracy : 0.9163\n",
            "Epoch: 3\tBatch: 450\tAvg-Loss: 0.2009\tTraining Accuracy : 0.9145\n",
            "Epoch: 3\tBatch: 500\tAvg-Loss: 0.1989\tTraining Accuracy : 0.9145\n",
            "Epoch: 3\tBatch: 550\tAvg-Loss: 0.1838\tTraining Accuracy : 0.9203\n",
            "Epoch: 3\tBatch: 600\tAvg-Loss: 0.1636\tTraining Accuracy : 0.9339\n",
            "Epoch: 3\tBatch: 650\tAvg-Loss: 0.1768\tTraining Accuracy : 0.9219\n",
            "Epoch: 3, Validation Loss: 1.660, Validation Accuracy: 0.544\n",
            "Epoch: 4\tBatch: 50\tAvg-Loss: 0.1523\tTraining Accuracy : 0.9386\n",
            "Epoch: 4\tBatch: 100\tAvg-Loss: 0.1576\tTraining Accuracy : 0.9345\n",
            "Epoch: 4\tBatch: 150\tAvg-Loss: 0.1610\tTraining Accuracy : 0.9356\n",
            "Epoch: 4\tBatch: 200\tAvg-Loss: 0.1464\tTraining Accuracy : 0.9403\n",
            "Epoch: 4\tBatch: 250\tAvg-Loss: 0.1438\tTraining Accuracy : 0.9425\n",
            "Epoch: 4\tBatch: 300\tAvg-Loss: 0.1510\tTraining Accuracy : 0.9381\n",
            "Epoch: 4\tBatch: 350\tAvg-Loss: 0.1512\tTraining Accuracy : 0.9372\n",
            "Epoch: 4\tBatch: 400\tAvg-Loss: 0.1499\tTraining Accuracy : 0.9395\n",
            "Epoch: 4\tBatch: 450\tAvg-Loss: 0.1415\tTraining Accuracy : 0.9402\n",
            "Epoch: 4\tBatch: 500\tAvg-Loss: 0.1409\tTraining Accuracy : 0.9417\n",
            "Epoch: 4\tBatch: 550\tAvg-Loss: 0.1432\tTraining Accuracy : 0.9406\n",
            "Epoch: 4\tBatch: 600\tAvg-Loss: 0.1390\tTraining Accuracy : 0.9427\n",
            "Epoch: 4\tBatch: 650\tAvg-Loss: 0.1344\tTraining Accuracy : 0.9416\n",
            "Epoch     5: reducing learning rate of group 0 to 7.0000e-02.\n",
            "Epoch: 4, Validation Loss: 1.598, Validation Accuracy: 0.519\n",
            "Epoch: 5\tBatch: 50\tAvg-Loss: 0.1166\tTraining Accuracy : 0.9541\n",
            "Epoch: 5\tBatch: 100\tAvg-Loss: 0.1060\tTraining Accuracy : 0.9580\n",
            "Epoch: 5\tBatch: 150\tAvg-Loss: 0.1038\tTraining Accuracy : 0.9591\n",
            "Epoch: 5\tBatch: 200\tAvg-Loss: 0.0987\tTraining Accuracy : 0.9598\n",
            "Epoch: 5\tBatch: 250\tAvg-Loss: 0.1029\tTraining Accuracy : 0.9608\n",
            "Epoch: 5\tBatch: 300\tAvg-Loss: 0.0951\tTraining Accuracy : 0.9598\n",
            "Epoch: 5\tBatch: 350\tAvg-Loss: 0.0866\tTraining Accuracy : 0.9672\n",
            "Epoch: 5\tBatch: 400\tAvg-Loss: 0.1020\tTraining Accuracy : 0.9572\n",
            "Epoch: 5\tBatch: 450\tAvg-Loss: 0.1013\tTraining Accuracy : 0.9573\n",
            "Epoch: 5\tBatch: 500\tAvg-Loss: 0.1031\tTraining Accuracy : 0.9573\n",
            "Epoch: 5\tBatch: 550\tAvg-Loss: 0.0903\tTraining Accuracy : 0.9614\n",
            "Epoch: 5\tBatch: 600\tAvg-Loss: 0.0892\tTraining Accuracy : 0.9625\n",
            "Epoch: 5\tBatch: 650\tAvg-Loss: 0.0937\tTraining Accuracy : 0.9616\n",
            "Epoch: 5, Validation Loss: 2.621, Validation Accuracy: 0.522\n",
            "Epoch: 6\tBatch: 50\tAvg-Loss: 0.0917\tTraining Accuracy : 0.9642\n",
            "Epoch: 6\tBatch: 100\tAvg-Loss: 0.0906\tTraining Accuracy : 0.9631\n",
            "Epoch: 6\tBatch: 150\tAvg-Loss: 0.0903\tTraining Accuracy : 0.9655\n",
            "Epoch: 6\tBatch: 200\tAvg-Loss: 0.0834\tTraining Accuracy : 0.9673\n",
            "Epoch: 6\tBatch: 250\tAvg-Loss: 0.0885\tTraining Accuracy : 0.9641\n",
            "Epoch: 6\tBatch: 300\tAvg-Loss: 0.0845\tTraining Accuracy : 0.9648\n",
            "Epoch: 6\tBatch: 350\tAvg-Loss: 0.0894\tTraining Accuracy : 0.9606\n",
            "Epoch: 6\tBatch: 400\tAvg-Loss: 0.0856\tTraining Accuracy : 0.9644\n",
            "Epoch: 6\tBatch: 450\tAvg-Loss: 0.0929\tTraining Accuracy : 0.9600\n",
            "Epoch: 6\tBatch: 500\tAvg-Loss: 0.0900\tTraining Accuracy : 0.9639\n",
            "Epoch: 6\tBatch: 550\tAvg-Loss: 0.0809\tTraining Accuracy : 0.9666\n",
            "Epoch: 6\tBatch: 600\tAvg-Loss: 0.0852\tTraining Accuracy : 0.9670\n",
            "Epoch: 6\tBatch: 650\tAvg-Loss: 0.0818\tTraining Accuracy : 0.9673\n",
            "Epoch: 6, Validation Loss: 2.462, Validation Accuracy: 0.529\n",
            "Epoch: 7\tBatch: 50\tAvg-Loss: 0.0761\tTraining Accuracy : 0.9731\n",
            "Epoch: 7\tBatch: 100\tAvg-Loss: 0.0856\tTraining Accuracy : 0.9656\n",
            "Epoch: 7\tBatch: 150\tAvg-Loss: 0.0830\tTraining Accuracy : 0.9663\n",
            "Epoch: 7\tBatch: 200\tAvg-Loss: 0.0818\tTraining Accuracy : 0.9670\n",
            "Epoch: 7\tBatch: 250\tAvg-Loss: 0.0771\tTraining Accuracy : 0.9692\n",
            "Epoch: 7\tBatch: 300\tAvg-Loss: 0.0826\tTraining Accuracy : 0.9680\n",
            "Epoch: 7\tBatch: 350\tAvg-Loss: 0.0827\tTraining Accuracy : 0.9677\n",
            "Epoch: 7\tBatch: 400\tAvg-Loss: 0.0783\tTraining Accuracy : 0.9719\n",
            "Epoch: 7\tBatch: 450\tAvg-Loss: 0.0828\tTraining Accuracy : 0.9630\n",
            "Epoch: 7\tBatch: 500\tAvg-Loss: 0.0780\tTraining Accuracy : 0.9698\n",
            "Epoch: 7\tBatch: 550\tAvg-Loss: 0.0861\tTraining Accuracy : 0.9661\n",
            "Epoch: 7\tBatch: 600\tAvg-Loss: 0.0925\tTraining Accuracy : 0.9606\n",
            "Epoch: 7\tBatch: 650\tAvg-Loss: 0.0827\tTraining Accuracy : 0.9663\n",
            "Epoch: 7, Validation Loss: 2.585, Validation Accuracy: 0.537\n",
            "Epoch: 8\tBatch: 50\tAvg-Loss: 0.0767\tTraining Accuracy : 0.9712\n",
            "Epoch: 8\tBatch: 100\tAvg-Loss: 0.0795\tTraining Accuracy : 0.9673\n",
            "Epoch: 8\tBatch: 150\tAvg-Loss: 0.0686\tTraining Accuracy : 0.9733\n",
            "Epoch: 8\tBatch: 200\tAvg-Loss: 0.0750\tTraining Accuracy : 0.9702\n",
            "Epoch: 8\tBatch: 250\tAvg-Loss: 0.0790\tTraining Accuracy : 0.9680\n",
            "Epoch: 8\tBatch: 300\tAvg-Loss: 0.0783\tTraining Accuracy : 0.9684\n",
            "Epoch: 8\tBatch: 350\tAvg-Loss: 0.0825\tTraining Accuracy : 0.9677\n",
            "Epoch: 8\tBatch: 400\tAvg-Loss: 0.0741\tTraining Accuracy : 0.9703\n",
            "Epoch: 8\tBatch: 450\tAvg-Loss: 0.0787\tTraining Accuracy : 0.9672\n",
            "Epoch: 8\tBatch: 500\tAvg-Loss: 0.0741\tTraining Accuracy : 0.9698\n",
            "Epoch: 8\tBatch: 550\tAvg-Loss: 0.0800\tTraining Accuracy : 0.9677\n",
            "Epoch: 8\tBatch: 600\tAvg-Loss: 0.0810\tTraining Accuracy : 0.9678\n",
            "Epoch: 8\tBatch: 650\tAvg-Loss: 0.0757\tTraining Accuracy : 0.9684\n",
            "Epoch     9: reducing learning rate of group 0 to 4.9000e-02.\n",
            "Epoch: 8, Validation Loss: 2.779, Validation Accuracy: 0.527\n",
            "Epoch: 9\tBatch: 50\tAvg-Loss: 0.0702\tTraining Accuracy : 0.9714\n",
            "Epoch: 9\tBatch: 100\tAvg-Loss: 0.0602\tTraining Accuracy : 0.9767\n",
            "Epoch: 9\tBatch: 150\tAvg-Loss: 0.0659\tTraining Accuracy : 0.9730\n",
            "Epoch: 9\tBatch: 200\tAvg-Loss: 0.0603\tTraining Accuracy : 0.9772\n",
            "Epoch: 9\tBatch: 250\tAvg-Loss: 0.0572\tTraining Accuracy : 0.9758\n",
            "Epoch: 9\tBatch: 300\tAvg-Loss: 0.0599\tTraining Accuracy : 0.9758\n",
            "Epoch: 9\tBatch: 350\tAvg-Loss: 0.0632\tTraining Accuracy : 0.9730\n",
            "Epoch: 9\tBatch: 400\tAvg-Loss: 0.0598\tTraining Accuracy : 0.9744\n",
            "Epoch: 9\tBatch: 450\tAvg-Loss: 0.0631\tTraining Accuracy : 0.9750\n",
            "Epoch: 9\tBatch: 500\tAvg-Loss: 0.0643\tTraining Accuracy : 0.9748\n",
            "Epoch: 9\tBatch: 550\tAvg-Loss: 0.0662\tTraining Accuracy : 0.9723\n",
            "Epoch: 9\tBatch: 600\tAvg-Loss: 0.0638\tTraining Accuracy : 0.9750\n",
            "Epoch: 9\tBatch: 650\tAvg-Loss: 0.0547\tTraining Accuracy : 0.9783\n",
            "Epoch: 9, Validation Loss: 3.026, Validation Accuracy: 0.542\n",
            "Epoch: 10\tBatch: 50\tAvg-Loss: 0.0609\tTraining Accuracy : 0.9753\n",
            "Epoch: 10\tBatch: 100\tAvg-Loss: 0.0569\tTraining Accuracy : 0.9781\n",
            "Epoch: 10\tBatch: 150\tAvg-Loss: 0.0568\tTraining Accuracy : 0.9764\n",
            "Epoch: 10\tBatch: 200\tAvg-Loss: 0.0596\tTraining Accuracy : 0.9761\n",
            "Epoch: 10\tBatch: 250\tAvg-Loss: 0.0605\tTraining Accuracy : 0.9756\n",
            "Epoch: 10\tBatch: 300\tAvg-Loss: 0.0601\tTraining Accuracy : 0.9752\n",
            "Epoch: 10\tBatch: 350\tAvg-Loss: 0.0640\tTraining Accuracy : 0.9738\n",
            "Epoch: 10\tBatch: 400\tAvg-Loss: 0.0626\tTraining Accuracy : 0.9762\n",
            "Epoch: 10\tBatch: 450\tAvg-Loss: 0.0628\tTraining Accuracy : 0.9739\n",
            "Epoch: 10\tBatch: 500\tAvg-Loss: 0.0577\tTraining Accuracy : 0.9745\n",
            "Epoch: 10\tBatch: 550\tAvg-Loss: 0.0546\tTraining Accuracy : 0.9752\n",
            "Epoch: 10\tBatch: 600\tAvg-Loss: 0.0619\tTraining Accuracy : 0.9755\n",
            "Epoch: 10\tBatch: 650\tAvg-Loss: 0.0599\tTraining Accuracy : 0.9775\n",
            "Epoch: 10, Validation Loss: 2.698, Validation Accuracy: 0.538\n",
            "Epoch: 11\tBatch: 50\tAvg-Loss: 0.0525\tTraining Accuracy : 0.9783\n",
            "Epoch: 11\tBatch: 100\tAvg-Loss: 0.0572\tTraining Accuracy : 0.9764\n",
            "Epoch: 11\tBatch: 150\tAvg-Loss: 0.0535\tTraining Accuracy : 0.9803\n",
            "Epoch: 11\tBatch: 200\tAvg-Loss: 0.0505\tTraining Accuracy : 0.9792\n",
            "Epoch: 11\tBatch: 250\tAvg-Loss: 0.0653\tTraining Accuracy : 0.9698\n",
            "Epoch: 11\tBatch: 300\tAvg-Loss: 0.0587\tTraining Accuracy : 0.9766\n",
            "Epoch: 11\tBatch: 350\tAvg-Loss: 0.0486\tTraining Accuracy : 0.9803\n",
            "Epoch: 11\tBatch: 400\tAvg-Loss: 0.0544\tTraining Accuracy : 0.9789\n",
            "Epoch: 11\tBatch: 450\tAvg-Loss: 0.0635\tTraining Accuracy : 0.9734\n",
            "Epoch: 11\tBatch: 500\tAvg-Loss: 0.0599\tTraining Accuracy : 0.9775\n",
            "Epoch: 11\tBatch: 550\tAvg-Loss: 0.0569\tTraining Accuracy : 0.9747\n",
            "Epoch: 11\tBatch: 600\tAvg-Loss: 0.0639\tTraining Accuracy : 0.9752\n",
            "Epoch: 11\tBatch: 650\tAvg-Loss: 0.0550\tTraining Accuracy : 0.9778\n",
            "Epoch: 11, Validation Loss: 2.803, Validation Accuracy: 0.542\n",
            "Epoch: 12\tBatch: 50\tAvg-Loss: 0.0525\tTraining Accuracy : 0.9791\n",
            "Epoch: 12\tBatch: 100\tAvg-Loss: 0.0484\tTraining Accuracy : 0.9812\n",
            "Epoch: 12\tBatch: 150\tAvg-Loss: 0.0505\tTraining Accuracy : 0.9788\n",
            "Epoch: 12\tBatch: 200\tAvg-Loss: 0.0502\tTraining Accuracy : 0.9800\n",
            "Epoch: 12\tBatch: 250\tAvg-Loss: 0.0631\tTraining Accuracy : 0.9736\n",
            "Epoch: 12\tBatch: 300\tAvg-Loss: 0.0619\tTraining Accuracy : 0.9734\n",
            "Epoch: 12\tBatch: 350\tAvg-Loss: 0.0623\tTraining Accuracy : 0.9767\n",
            "Epoch: 12\tBatch: 400\tAvg-Loss: 0.0620\tTraining Accuracy : 0.9731\n",
            "Epoch: 12\tBatch: 450\tAvg-Loss: 0.0560\tTraining Accuracy : 0.9781\n",
            "Epoch: 12\tBatch: 500\tAvg-Loss: 0.0595\tTraining Accuracy : 0.9784\n",
            "Epoch: 12\tBatch: 550\tAvg-Loss: 0.0547\tTraining Accuracy : 0.9756\n",
            "Epoch: 12\tBatch: 600\tAvg-Loss: 0.0599\tTraining Accuracy : 0.9742\n",
            "Epoch: 12\tBatch: 650\tAvg-Loss: 0.0577\tTraining Accuracy : 0.9762\n",
            "Epoch    13: reducing learning rate of group 0 to 3.4300e-02.\n",
            "Epoch: 12, Validation Loss: 2.797, Validation Accuracy: 0.541\n",
            "Epoch: 13\tBatch: 50\tAvg-Loss: 0.0547\tTraining Accuracy : 0.9789\n",
            "Epoch: 13\tBatch: 100\tAvg-Loss: 0.0522\tTraining Accuracy : 0.9786\n",
            "Epoch: 13\tBatch: 150\tAvg-Loss: 0.0441\tTraining Accuracy : 0.9817\n",
            "Epoch: 13\tBatch: 200\tAvg-Loss: 0.0471\tTraining Accuracy : 0.9805\n",
            "Epoch: 13\tBatch: 250\tAvg-Loss: 0.0438\tTraining Accuracy : 0.9825\n",
            "Epoch: 13\tBatch: 300\tAvg-Loss: 0.0442\tTraining Accuracy : 0.9805\n",
            "Epoch: 13\tBatch: 350\tAvg-Loss: 0.0533\tTraining Accuracy : 0.9772\n",
            "Epoch: 13\tBatch: 400\tAvg-Loss: 0.0446\tTraining Accuracy : 0.9819\n",
            "Epoch: 13\tBatch: 450\tAvg-Loss: 0.0449\tTraining Accuracy : 0.9812\n",
            "Epoch: 13\tBatch: 500\tAvg-Loss: 0.0447\tTraining Accuracy : 0.9816\n",
            "Epoch: 13\tBatch: 550\tAvg-Loss: 0.0483\tTraining Accuracy : 0.9798\n",
            "Epoch: 13\tBatch: 600\tAvg-Loss: 0.0467\tTraining Accuracy : 0.9812\n",
            "Epoch: 13\tBatch: 650\tAvg-Loss: 0.0481\tTraining Accuracy : 0.9794\n",
            "Epoch: 13, Validation Loss: 3.480, Validation Accuracy: 0.534\n",
            "Epoch: 14\tBatch: 50\tAvg-Loss: 0.0434\tTraining Accuracy : 0.9817\n",
            "Epoch: 14\tBatch: 100\tAvg-Loss: 0.0437\tTraining Accuracy : 0.9831\n",
            "Epoch: 14\tBatch: 150\tAvg-Loss: 0.0481\tTraining Accuracy : 0.9792\n",
            "Epoch: 14\tBatch: 200\tAvg-Loss: 0.0425\tTraining Accuracy : 0.9816\n",
            "Epoch: 14\tBatch: 250\tAvg-Loss: 0.0448\tTraining Accuracy : 0.9811\n",
            "Epoch: 14\tBatch: 300\tAvg-Loss: 0.0401\tTraining Accuracy : 0.9847\n",
            "Epoch: 14\tBatch: 350\tAvg-Loss: 0.0438\tTraining Accuracy : 0.9811\n",
            "Epoch: 14\tBatch: 400\tAvg-Loss: 0.0505\tTraining Accuracy : 0.9808\n",
            "Epoch: 14\tBatch: 450\tAvg-Loss: 0.0456\tTraining Accuracy : 0.9817\n",
            "Epoch: 14\tBatch: 500\tAvg-Loss: 0.0497\tTraining Accuracy : 0.9777\n",
            "Epoch: 14\tBatch: 550\tAvg-Loss: 0.0446\tTraining Accuracy : 0.9838\n",
            "Epoch: 14\tBatch: 600\tAvg-Loss: 0.0477\tTraining Accuracy : 0.9798\n",
            "Epoch: 14\tBatch: 650\tAvg-Loss: 0.0457\tTraining Accuracy : 0.9834\n",
            "Epoch: 14, Validation Loss: 3.147, Validation Accuracy: 0.534\n",
            "Epoch: 15\tBatch: 50\tAvg-Loss: 0.0417\tTraining Accuracy : 0.9811\n",
            "Epoch: 15\tBatch: 100\tAvg-Loss: 0.0462\tTraining Accuracy : 0.9812\n",
            "Epoch: 15\tBatch: 150\tAvg-Loss: 0.0367\tTraining Accuracy : 0.9853\n",
            "Epoch: 15\tBatch: 200\tAvg-Loss: 0.0487\tTraining Accuracy : 0.9795\n",
            "Epoch: 15\tBatch: 250\tAvg-Loss: 0.0433\tTraining Accuracy : 0.9825\n",
            "Epoch: 15\tBatch: 300\tAvg-Loss: 0.0460\tTraining Accuracy : 0.9795\n",
            "Epoch: 15\tBatch: 350\tAvg-Loss: 0.0412\tTraining Accuracy : 0.9830\n",
            "Epoch: 15\tBatch: 400\tAvg-Loss: 0.0479\tTraining Accuracy : 0.9803\n",
            "Epoch: 15\tBatch: 450\tAvg-Loss: 0.0442\tTraining Accuracy : 0.9817\n",
            "Epoch: 15\tBatch: 500\tAvg-Loss: 0.0438\tTraining Accuracy : 0.9827\n",
            "Epoch: 15\tBatch: 550\tAvg-Loss: 0.0409\tTraining Accuracy : 0.9836\n",
            "Epoch: 15\tBatch: 600\tAvg-Loss: 0.0414\tTraining Accuracy : 0.9841\n",
            "Epoch: 15\tBatch: 650\tAvg-Loss: 0.0439\tTraining Accuracy : 0.9823\n",
            "Epoch: 15, Validation Loss: 3.546, Validation Accuracy: 0.539\n",
            "Epoch: 16\tBatch: 50\tAvg-Loss: 0.0356\tTraining Accuracy : 0.9861\n",
            "Epoch: 16\tBatch: 100\tAvg-Loss: 0.0393\tTraining Accuracy : 0.9834\n",
            "Epoch: 16\tBatch: 150\tAvg-Loss: 0.0444\tTraining Accuracy : 0.9806\n",
            "Epoch: 16\tBatch: 200\tAvg-Loss: 0.0434\tTraining Accuracy : 0.9816\n",
            "Epoch: 16\tBatch: 250\tAvg-Loss: 0.0450\tTraining Accuracy : 0.9814\n",
            "Epoch: 16\tBatch: 300\tAvg-Loss: 0.0429\tTraining Accuracy : 0.9816\n",
            "Epoch: 16\tBatch: 350\tAvg-Loss: 0.0483\tTraining Accuracy : 0.9797\n",
            "Epoch: 16\tBatch: 400\tAvg-Loss: 0.0437\tTraining Accuracy : 0.9828\n",
            "Epoch: 16\tBatch: 450\tAvg-Loss: 0.0438\tTraining Accuracy : 0.9828\n",
            "Epoch: 16\tBatch: 500\tAvg-Loss: 0.0414\tTraining Accuracy : 0.9825\n",
            "Epoch: 16\tBatch: 550\tAvg-Loss: 0.0456\tTraining Accuracy : 0.9816\n",
            "Epoch: 16\tBatch: 600\tAvg-Loss: 0.0533\tTraining Accuracy : 0.9786\n",
            "Epoch: 16\tBatch: 650\tAvg-Loss: 0.0458\tTraining Accuracy : 0.9811\n",
            "Epoch    17: reducing learning rate of group 0 to 2.4010e-02.\n",
            "Epoch: 16, Validation Loss: 3.387, Validation Accuracy: 0.544\n",
            "Epoch: 17\tBatch: 50\tAvg-Loss: 0.0404\tTraining Accuracy : 0.9855\n",
            "Epoch: 17\tBatch: 100\tAvg-Loss: 0.0390\tTraining Accuracy : 0.9838\n",
            "Epoch: 17\tBatch: 150\tAvg-Loss: 0.0385\tTraining Accuracy : 0.9838\n",
            "Epoch: 17\tBatch: 200\tAvg-Loss: 0.0418\tTraining Accuracy : 0.9828\n",
            "Epoch: 17\tBatch: 250\tAvg-Loss: 0.0373\tTraining Accuracy : 0.9834\n",
            "Epoch: 17\tBatch: 300\tAvg-Loss: 0.0369\tTraining Accuracy : 0.9825\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a99168917ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnum_train_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vIdH8nTXpno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b883c988-f6d2-4dea-a76a-76a931d16478"
      },
      "source": [
        "# Test\n",
        "network.load_state_dict(torch.load(\"/content/gdrive/MyDrive/baseline_6channels/model_16.pt\"))\n",
        "\n",
        "with torch.no_grad():\n",
        "  network.eval()\n",
        "  num_correct = 0\n",
        "  for batch_num, (x, y) in enumerate(test_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    outputs = network(x)\n",
        "    num_correct += (torch.argmax(outputs, axis=1) == y).sum().item()\n",
        "\n",
        "  test_acc = num_correct / len(test_set)\n",
        "  print(test_acc)\n"
      ],
      "id": "6vIdH8nTXpno",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5082662845806238\n"
          ]
        }
      ]
    }
  ]
}
